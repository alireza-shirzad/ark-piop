use super::structs::{
    ProcessedSNARKPk, ProverState,
    proof::{PCSSubproof, SNARKProof},
};
use crate::{
    SnarkBackend,
    structs::claim::{TrackerLookupClaim, TrackerNoZerocheckClaim},
};
use crate::{
    arithmetic::mat_poly::utils::evaluate_with_eq, prover::tracker::SnarkError::ProverError,
};
use crate::{
    arithmetic::{
        mat_poly::{lde::LDE, mle::MLE, utils::build_eq_x_r},
        virt_poly::{
            VirtualPoly,
            hp_interface::{HPVirtualPolynomial, VPAuxInfo},
        },
    },
    errors::{SnarkError, SnarkResult},
    pcs::PCS,
    piop::{structs::SumcheckProof, sum_check::SumCheck},
    setup::{
        errors::SetupError::NoRangePoly,
        structs::{SNARKPk, SNARKVk},
    },
    structs::{
        PCSOpeningProof, SumcheckSubproof, TrackerID,
        claim::{TrackerSumcheckClaim, TrackerZerocheckClaim},
    },
};
use crate::{
    prover::{errors::HonestProverError::FalseClaim, structs::TrackerEvalClaim},
    prover::{errors::ProverError::HonestProverError, structs::polynomial::TrackedPoly},
};
use ark_ec::AdditiveGroup;
use ark_ff::batch_inversion;
use ark_poly::Polynomial;
use ark_std::One;
use ark_std::Zero;
use ark_std::{cfg_iter, cfg_iter_mut};
use derivative::Derivative;

#[cfg(feature = "parallel")]
use rayon::prelude::*;
use std::{
    collections::{BTreeMap, BTreeSet, HashMap, HashSet},
    mem::take,
    panic,
    sync::Arc,
};
use tracing::{debug, instrument, trace};
/// The Tracker is a data structure for creating and managing virtual
/// polynomials and their comitments. It is in charge of  
///  1) Recording the structure of virtual polynomials and
///     their products
///  2) Recording the structure of virtual polynomials and
///     their products
///  3) Recording the comitments of virtual polynomials and
///     their products
///  4) Providing methods for adding virtual polynomials
///     together

// Clone is only implemented if PCS satisfies the PCS<F>
// bound, which guarantees that PCS::ProverParam
#[derive(Derivative)]
#[derivative(Clone(bound = ""))]
// #[derivative(Clone(bound = "MvPCS: Clone, UvPCS: Clone"))]
pub struct ProverTracker<B>
where
    B: SnarkBackend,
{
    pub pk: ProcessedSNARKPk<B>,
    pub state: ProverState<B>,
}

impl<B> ProverTracker<B>
where
    B: SnarkBackend,
{
    pub fn new_from_pk(pk: SNARKPk<B>) -> Self {
        let mut tracker = Self {
            pk: ProcessedSNARKPk::new_from_pk(&pk),
            state: ProverState::default(),
        };
        tracker.add_vk_to_transcript(pk.vk.clone());
        tracker
    }

    fn add_vk_to_transcript(&mut self, vk: SNARKVk<B>) {
        self.state
            .transcript
            .append_serializable_element(b"vk", &vk)
            .unwrap();
        vk.indexed_coms.iter().for_each(|(_, comm)| {
            self.state
                .transcript
                .append_serializable_element(b"comm", comm)
                .unwrap();
        });
    }

    pub(crate) fn set_indexed_tracked_polys(
        &mut self,
        range_tr_polys: BTreeMap<String, TrackedPoly<B>>,
    ) {
        self.state.indexed_tracked_polys = range_tr_polys;
    }

    /// Get the range tracked polynomial given the data type
    pub fn indexed_tracked_poly(&self, label: String) -> SnarkResult<TrackedPoly<B>> {
        match self.state.indexed_tracked_polys.get(&label) {
            Some(poly) => Ok(poly.clone()),
            _ => Err(SnarkError::SetupError(NoRangePoly(format!("{:?}", label)))),
        }
    }

    pub fn add_indexed_tracked_poly(
        &mut self,
        label: String,
        poly: TrackedPoly<B>,
    ) -> Option<TrackedPoly<B>> {
        self.state.indexed_tracked_polys.insert(label, poly)
    }

    /// Generates a new `TrackerID`.
    ///
    /// This function increments an internal counter and returns a new
    /// `TrackerID` based on the current value of the counter. It ensures
    /// that each generated `TrackerID` is unique.
    pub fn gen_id(&mut self) -> TrackerID {
        let id = self.state.num_tracked_polys;
        self.state.num_tracked_polys += 1;
        TrackerID(id)
    }

    /// Peek at the next `TrackerID` that will be generated by gen_id.
    pub fn next_id(&mut self) -> TrackerID {
        TrackerID(self.state.num_tracked_polys)
    }

    // Peek at the next TrackerID without incrementing the counter
    pub(crate) fn peek_next_id(&mut self) -> TrackerID {
        TrackerID(self.state.num_tracked_polys)
    }

    /// Tracks a materialized polynomial.
    ///
    /// moves the polynomial to heap, assigns a TracckerID to it in map and
    /// returns the TrackerID
    pub fn track_mat_mv_poly(&mut self, polynomial: MLE<B::F>) -> TrackerID {
        let polynomial = Arc::new(polynomial);
        self.track_mat_arc_mv_poly(polynomial)
    }

    /// Tracks a materialized polynomial.
    ///
    /// moves the polynomial to heap, assigns a TracckerID to it in map and
    /// returns the TrackerID
    pub fn track_mat_uv_poly(&mut self, polynomial: LDE<B::F>) -> TrackerID {
        let polynomial = Arc::new(polynomial);
        self.track_mat_arc_uv_poly(polynomial)
    }
    /// Tracks materialized polynomial by reference.
    ///
    /// Assumes the input polynomial is already on the heap and assigns a
    /// TrackerID to it in the map
    fn track_mat_arc_mv_poly(&mut self, polynomial: Arc<MLE<B::F>>) -> TrackerID {
        // Create the new TrackerID
        let poly_id = self.gen_id();

        // Add the polynomial to the materialized map
        self.state
            .mv_pcs_substate
            .materialized_polys
            .insert(poly_id, polynomial.clone());
        self.state.num_vars.insert(poly_id, polynomial.num_vars());
        // Return the new TrackerID
        poly_id
    }

    fn track_mat_arc_uv_poly(&mut self, polynomial: Arc<LDE<B::F>>) -> TrackerID {
        // Create the new TrackerID
        let poly_id = self.gen_id();

        // Add the polynomial to the materialized map
        self.state
            .uv_pcs_substate
            .materialized_polys
            .insert(poly_id, polynomial.clone());

        // Return the new TrackerID
        poly_id
    }

    /// Tracks a materialized polynomial and sends a commitment to the verifier.
    pub fn track_and_commit_mat_mv_p(&mut self, polynomial: &MLE<B::F>) -> SnarkResult<TrackerID> {
        let polynomial = Arc::new(polynomial.clone());
        // commit to the polynomial
        let commitment = B::MvPCS::commit(self.pk.mv_pcs_param.as_ref(), &polynomial)?;
        Self::track_mat_mv_p_and_commitment(self, &polynomial, commitment)
    }

    pub fn track_mat_mv_p_and_commitment(
        &mut self,
        polynomial: &MLE<B::F>,
        commitment: <B::MvPCS as PCS<B::F>>::Commitment,
    ) -> SnarkResult<TrackerID> {
        let polynomial = Arc::new(polynomial.clone());
        // commit to the polynomial

        // track the polynomial and get its id
        let poly_id = self.track_mat_arc_mv_poly(polynomial);

        // add the commitment to the commitment map with the same poly_id
        self.state
            .mv_pcs_substate
            .materialized_comms
            .insert(poly_id, commitment.clone());

        // Add the commitment to the transcript, since it will be sent to the verifier
        self.state
            .transcript
            .append_serializable_element(b"comm", &commitment)?;
        // Return the new TrackerID
        Ok(poly_id)
    }

    pub fn track_and_commit_mat_uv_poly(
        &mut self,
        polynomial: LDE<B::F>,
    ) -> SnarkResult<TrackerID> {
        let polynomial = Arc::new(polynomial);
        // commit to the polynomial
        let commitment = B::UvPCS::commit(self.pk.uv_pcs_param.as_ref(), &polynomial)?;
        Self::track_mat_uv_p_and_commitment(self, &polynomial, commitment)
    }

    fn track_mat_uv_p_and_commitment(
        &mut self,
        polynomial: &LDE<B::F>,
        commitment: <B::UvPCS as PCS<B::F>>::Commitment,
    ) -> SnarkResult<TrackerID> {
        let polynomial = Arc::new(polynomial.clone());

        // track the polynomial and get its id
        let poly_id = self.track_mat_arc_uv_poly(polynomial);

        // add the commitment to the commitment map with the same poly_id
        self.state
            .uv_pcs_substate
            .materialized_comms
            .insert(poly_id, commitment.clone());

        // Add the commitment to the transcript, since it will be sent to the verifier
        self.state
            .transcript
            .append_serializable_element(b"comm", &commitment)?;
        // Return the new TrackerID
        Ok(poly_id)
    }

    /// Tracks a virtual polynomial
    ///
    /// generates a new TrackerID and adds the virtual polynomial to the map
    fn track_virt_poly(&mut self, p: VirtualPoly<B::F>) -> TrackerID {
        let poly_id = self.gen_id();

        let nv = p
            .iter()
            .flat_map(|(_, prod_ids)| prod_ids.iter().map(|id| self.state.num_vars[id]))
            .max()
            .unwrap_or_default();
        self.state.num_vars.insert(poly_id, nv);
        self.state.virtual_polys.insert(poly_id, p);
        // No need to commit to virtual polynomials
        poly_id
    }

    /// Get a reference to a materialized multivariate polynomial on the heap,
    /// from the map, by its TrackerID
    pub fn mat_mv_poly(&self, id: TrackerID) -> Option<&Arc<MLE<B::F>>> {
        self.state.mv_pcs_substate.materialized_polys.get(&id)
    }

    /// Get a reference to a materialized univariate polynomial on the heap,
    /// from the map, by its TrackerID
    pub fn mat_uv_poly(&self, id: TrackerID) -> Option<&Arc<LDE<B::F>>> {
        self.state.uv_pcs_substate.materialized_polys.get(&id)
    }

    /// Get a virtual polynomial, from the map, by its TrackerID
    pub fn virt_poly(&self, id: TrackerID) -> Option<&VirtualPoly<B::F>> {
        self.state.virtual_polys.get(&id)
    }
    fn extract_mv_openable_ids(&self, id: TrackerID) -> BTreeSet<TrackerID> {
        if self
            .state
            .mv_pcs_substate
            .materialized_comms
            .contains_key(&id)
        {
            return BTreeSet::from([id]);
        }
        let poly = self.virt_poly(id).unwrap();
        // 1)  Initialise the DFS stack with every TrackerID mentioned up-front
        let mut stack: Vec<TrackerID> = poly
            .iter()
            .flat_map(|(_, ids)| ids.iter().copied())
            .collect();

        let mut openable = BTreeSet::new();
        let mut visited = HashSet::new();

        // 2)  Standard iterative DFS
        while let Some(id) = stack.pop() {
            if !visited.insert(id) {
                continue; // already explored
            }

            // a) leaf with concrete commitment?
            if self
                .state
                .mv_pcs_substate
                .materialized_comms
                .contains_key(&id)
            {
                openable.insert(id);
                continue; // do *not* push children
            }

            // b) otherwise follow the virtual-poly reference if it exists
            if let Some(vpoly) = self.state.virtual_polys.get(&id) {
                for (_, child_ids) in vpoly.iter() {
                    stack.extend(child_ids.iter().copied());
                }
            }
            // c) dangling reference ⇒ silently ignore
        }

        openable
    }

    fn extract_uv_openable_ids(&self, id: TrackerID) -> BTreeSet<TrackerID> {
        if self
            .state
            .uv_pcs_substate
            .materialized_comms
            .contains_key(&id)
        {
            return BTreeSet::from([id]);
        }
        let poly = self.virt_poly(id).unwrap();
        // 1)  Initialise the DFS stack with every TrackerID mentioned up-front
        let mut stack: Vec<TrackerID> = poly
            .iter()
            .flat_map(|(_, ids)| ids.iter().copied())
            .collect();

        let mut openable = BTreeSet::new();
        let mut visited = HashSet::new();

        // 2)  Standard iterative DFS
        while let Some(id) = stack.pop() {
            if !visited.insert(id) {
                continue; // already explored
            }

            // a) leaf with concrete commitment?
            if self
                .state
                .uv_pcs_substate
                .materialized_comms
                .contains_key(&id)
            {
                openable.insert(id);
                continue; // do *not* push children
            }

            // b) otherwise follow the virtual-poly reference if it exists
            if let Some(vpoly) = self.state.virtual_polys.get(&id) {
                for (_, child_ids) in vpoly.iter() {
                    stack.extend(child_ids.iter().copied());
                }
            }
            // c) dangling reference ⇒ silently ignore
        }

        openable
    }

    /// Get the number of variables of a polynomial, by its TrackerID
    pub fn poly_nv(&self, id: TrackerID) -> usize {
        self.state.num_vars.get(&id).copied().unwrap()
    }

    /// Return the max multiplicative degree (max number of MLEs in any product)
    /// of the virtual-poly tree rooted at `id`, matching HPVirtualPolynomial::max_degree.
    pub fn virt_poly_degree(&self, id: TrackerID) -> usize {
        let mut memo = HashMap::new();
        let mut visiting = HashSet::new();
        self.virt_poly_degree_inner(id, &mut memo, &mut visiting)
    }

    fn virt_poly_degree_inner(
        &self,
        id: TrackerID,
        memo: &mut HashMap<TrackerID, usize>,
        visiting: &mut HashSet<TrackerID>,
    ) -> usize {
        if let Some(&cached) = memo.get(&id) {
            return cached;
        }
        if self.mat_mv_poly(id).is_some() {
            memo.insert(id, 1);
            return 1;
        }
        let Some(vpoly) = self.state.virtual_polys.get(&id) else {
            return 0;
        };
        if !visiting.insert(id) {
            return 0;
        }
        let mut max_degree = 0;
        for (_, prod_ids) in vpoly.iter() {
            let mut term_degree = 0;
            for child_id in prod_ids {
                term_degree += self.virt_poly_degree_inner(*child_id, memo, visiting);
            }
            if term_degree > max_degree {
                max_degree = term_degree;
            }
        }
        visiting.remove(&id);
        memo.insert(id, max_degree);
        max_degree
    }

    /// Adds/Subtracts two polynomials together
    /// The two polynomials are identified by their TrackerIDs, Each one can be
    /// either materialized or virtual
    /// The output is a tracker to a new virtual polynomial
    pub fn add_sub_polys(&mut self, p1: TrackerID, p2: TrackerID, do_sub: bool) -> TrackerID {
        let sign_coeff: B::F = if do_sub { -B::F::one() } else { B::F::one() };

        let p1_mat = self.mat_mv_poly(p1);
        let p1_virt = self.virt_poly(p1);
        let p2_mat = self.mat_mv_poly(p2);
        let p2_virt = self.virt_poly(p2);

        let mut new = VirtualPoly::new(); // Invariant: contains only material TrackerIDs
        match (p1_mat, p1_virt, p2_mat, p2_virt) {
            (Some(_), None, Some(_), None) => {
                new.push((B::F::one(), vec![p1]));
                new.push((sign_coeff, vec![p2]));
            }

            // p1: materialized, p2: virtual
            (Some(_), None, None, Some(p2)) => {
                new.push((B::F::one(), vec![p1]));
                new.extend(
                    p2.iter()
                        .map(|(coeff, prod)| (*coeff * sign_coeff, prod.clone())),
                );
            }
            // p1: virtual, p2: materialized
            (None, Some(p1), Some(_), None) => {
                new.push((sign_coeff, vec![p2]));
                new.extend_from_slice(p1);
            }
            (None, Some(p1), None, Some(p2)) => {
                new.extend_from_slice(p1);
                new.extend(
                    p2.iter()
                        .map(|(coeff, prod)| (*coeff * sign_coeff, prod.clone())),
                );
            }
            (None, None, _, _) => panic!("Unknown p1 TrackerID {p1:?}"),
            (_, _, None, None) => panic!("Unknown p2 TrackerID {p2:?}"),
            (_, _, _, _) => unreachable!(),
        }
        self.track_virt_poly(new)
    }

    /// Adds two polynomials together
    /// The two polynomials are identified by their TrackerIDs, Each one can be
    /// either materialized or virtual
    /// The output is a tracker to a new virtual polynomial
    pub fn add_polys(&mut self, p1_id: TrackerID, p2_id: TrackerID) -> TrackerID {
        self.add_sub_polys(p1_id, p2_id, false)
    }

    /// Subtracts p2 from p1
    /// The two polynomials are identified by their TrackerIDs, Each one can be
    /// either materialized or virtual
    /// The output is a tracker to a new virtual polynomial
    pub fn sub_polys(&mut self, p1_id: TrackerID, p2_id: TrackerID) -> TrackerID {
        self.add_sub_polys(p1_id, p2_id, true)
    }

    /// Multiplies two polynomials together
    /// The two polynomials are identified by their TrackerIDs, Each one can be
    /// either materialized or virtual
    /// The output is a tracker to a new virtual polynomial
    pub fn mul_polys(&mut self, p1: TrackerID, p2: TrackerID) -> TrackerID {
        let p1_mat = self.mat_mv_poly(p1);
        let p1_virt = self.virt_poly(p1);
        let p2_mat = self.mat_mv_poly(p2);
        let p2_virt = self.virt_poly(p2);

        let mut new = VirtualPoly::new(); // Invariant: contains only material TrackerIDs
        match (p1_mat, p1_virt, p2_mat, p2_virt) {
            // Bad Case: p1 not found
            (None, None, ..) => panic!("Unknown p1 TrackerID {p1:?}"),
            // Bad Case: p2 not found
            (_, _, None, None) => panic!("Unknown p1 TrackerID {p2:?}"),
            // Case 1: both p1 and p2 are materialized
            (Some(_), None, Some(_), None) => new.push((B::F::one(), vec![p1, p2])),
            // Case 2: p1 is materialized and p2 is virtual
            (Some(_), None, None, Some(p)) => {
                p.iter().cloned().for_each(|(coeff, mut prod)| {
                    prod.push(p1);
                    new.push((coeff, prod));
                });
            }
            (None, Some(p), Some(_), None) => {
                p.iter().cloned().for_each(|(coeff, mut prod)| {
                    prod.push(p2);
                    new.push((coeff, prod));
                });
            }
            // Case 3: both p1 and p2 are virtual
            (None, Some(p1), None, Some(p2)) => {
                for (coeff1, prod1) in p1 {
                    for (coeff2, prod2) in p2 {
                        let mut prod1 = prod1.clone();
                        prod1.extend_from_slice(prod2);
                        new.push((*coeff1 * *coeff2, prod1));
                    }
                }
            }
            (_, _, _, _) => unreachable!(),
        };
        self.track_virt_poly(new)
    }

    /// Adds a scalar to a polynomial, returns a new virtual polynomial
    // TODO: Can we do it more efficiently?
    pub fn add_scalar(&mut self, poly_id: TrackerID, c: B::F) -> TrackerID {
        let nv = self.poly_nv(poly_id);
        let scalar_mle = MLE::from_evaluations_vec(nv, vec![c; 2_usize.pow(nv as u32)]);
        let scalar_id = self.track_mat_mv_poly(scalar_mle);
        self.add_polys(poly_id, scalar_id)
    }

    /// Multiplies a polynomial by a scalar, returns a new virtual polynomial
    pub fn mul_scalar(&mut self, poly_id: TrackerID, c: B::F) -> TrackerID {
        let mut new = VirtualPoly::new();
        match self.mat_mv_poly(poly_id) {
            Some(_) => new.push((c, vec![poly_id])),
            None => {
                let p = self.virt_poly(poly_id).unwrap();
                p.iter().for_each(|(coeff, prod)| {
                    new.push((*coeff * c, prod.clone()));
                });
            }
        }
        self.track_virt_poly(new)
    }

    fn materialize_poly(&mut self, id: TrackerID) -> Arc<MLE<B::F>> {
        match self.mat_mv_poly(id) {
            Some(mat_poly) => return mat_poly.clone(), // already materialized
            None => {
                let virt_poly = self.state.virtual_polys[&id].clone();
                // Invariant: contains only material PolyIDs
                assert!(
                    virt_poly
                        .iter()
                        .all(|(_, ids)| ids.iter().all(|id| self.mat_mv_poly(*id).is_some()))
                );
                // Ensure all the product polynomials have the same number of variables
                // assert_eq!(
                //     virt_poly
                //         .iter()
                //         .flat_map(|(_, ids)| ids.iter().map(|id| self.poly_nv(*id)))
                //         .collect::<HashSet<_>>()
                //         .len(),
                //     1
                // );
                let nv = self.poly_nv(id);

                let evals = virt_poly.iter().fold(
                    vec![B::F::ZERO; 1 << nv],
                    |mut acc, (coeff, products)| {
                        let t = products.iter().fold(vec![*coeff; 1 << nv], |mut acc, id| {
                            cfg_iter_mut!(acc)
                                .zip(self.mat_mv_poly(*id).unwrap().evaluations())
                                .for_each(|(a, b)| *a *= b);
                            acc
                        });
                        cfg_iter_mut!(acc).zip(t).for_each(|(a, b)| *a += b);
                        acc
                    },
                );
                Arc::new(MLE::from_evaluations_vec(nv, evals))
            }
        }
    }

    pub fn evaluate_uv(&self, id: TrackerID, pt: &B::F) -> Option<B::F> {
        let mat_poly = self.state.uv_pcs_substate.materialized_polys.get(&id);
        // TODO: Change this to_vec
        mat_poly.map(|poly| poly.evaluate(pt))
    }

    /// Evaluates a polynomial at a point
    pub fn evaluate_mv(&self, id: TrackerID, pt: &[B::F]) -> Option<B::F> {
        match self.state.mv_pcs_substate.materialized_polys.get(&id) {
            Some(poly) => {
                let nv = poly.mat_mle().num_vars;
                if nv == 0 {
                    // Avoid build_eq_x_r([]) for constant polynomials.
                    return poly.mat_mle().evaluations.get(0).copied();
                }
                let eq_eval = build_eq_x_r(&pt[..nv]).unwrap();
                Some(evaluate_with_eq(poly, &eq_eval))
            }
            None => {
                let p = self.virt_poly(id).unwrap();
                // calculate the evaluation of each product list
                let result = p
                    .iter()
                    .map(|(coeff, prod)| {
                        *coeff
                            * prod
                                .iter()
                                .map(|poly| self.evaluate_mv(*poly, pt).unwrap())
                                .product::<B::F>()
                    })
                    .sum::<B::F>();
                Some(result)
            }
        }
    }

    /// Evaluates a polynomial at a point given the evaluations of the eq polynomial at that point.
    /// This assumes that `eq_evals` contains the evaluations of the eq polynomial for each number
    /// of variables of the *actual* underlying `DenseMultilinearExtension` of the materialized polynomials.
    pub fn evaluate_mv_with_eq_evals(
        &self,
        id: TrackerID,
        eq_evals: &BTreeMap<usize, MLE<B::F>>,
    ) -> Option<B::F> {
        match self.state.mv_pcs_substate.materialized_polys.get(&id) {
            Some(poly) => {
                let nv = poly.mat_mle().num_vars;
                Some(evaluate_with_eq(poly, &eq_evals[&nv]))
            }
            None => {
                let p = self.virt_poly(id).unwrap();
                let result = p
                    .iter()
                    .map(|(coeff, prod)| {
                        *coeff
                            * prod
                                .iter()
                                .map(|poly| {
                                    self.evaluate_mv_with_eq_evals(*poly, eq_evals).unwrap()
                                })
                                .product::<B::F>()
                    })
                    .sum::<B::F>();
                Some(result)
            }
        }
    }

    /// Returns the evaluations of a polynomial on the boolean hypercube
    pub fn evaluations(&mut self, id: TrackerID) -> Vec<B::F> {
        // Ensure the polynomial is materialized before getting evaluations
        let mat_poly = self.materialize_poly(id);

        mat_poly.evaluations()
    }

    /// Generate the challenge from the current transcript
    /// and append it to the transcript.
    pub fn get_and_append_challenge(&mut self, label: &'static [u8]) -> SnarkResult<B::F> {
        self.state
            .transcript
            .get_and_append_challenge(label)
            .map_err(SnarkError::from)
    }

    /// Adds a sumcheck claim to the list of the sumcheck claims of the prover
    /// a sumcheck claim is of the form (poly_id, claimed_sum) which means that
    /// the prover claims that the sum of the evaluations of the polynomial with
    /// poly_id is claimed_sum
    // TODO: Remove the claimed_sum
    pub fn add_mv_sumcheck_claim(
        &mut self,
        poly_id: TrackerID,
        claimed_sum: B::F,
    ) -> SnarkResult<()> {
        #[cfg(feature = "honest-prover")]
        {
            let evals = self.evaluations(poly_id);
            let real_sum = cfg_iter!(evals).sum::<B::F>();
            if real_sum != claimed_sum {
                tracing::error!(
                    "honest prover sumcheck mismatch: real_sum={:?} claimed_sum={:?}",
                    real_sum,
                    claimed_sum
                );
                return Err(ProverError(HonestProverError(FalseClaim)));
            }
        }
        self.state
            .mv_pcs_substate
            .sum_check_claims
            .push(TrackerSumcheckClaim::new(poly_id, claimed_sum));
        Ok(())
    }

    /// Adds a zerocheck claim to the list of the zerocheck claims of the prover
    /// a zerocheck claim is of the form (poly_id) which means that the prover
    /// claims that the polynomial with poly_id evaluates to zero all over the
    /// boolean hypercube
    pub fn add_mv_zerocheck_claim(&mut self, poly_id: TrackerID) -> SnarkResult<()> {
        if let Some(poly) = self.virt_poly(poly_id) {
            trace!(?poly_id, ?poly, "add_mv_zerocheck_claim virtual");
        } else {
            trace!(?poly_id, "add_mv_zerocheck_claim materialized");
        }
        #[cfg(feature = "honest-prover")]
        {
            let evals = self.evaluations(poly_id);
            if cfg_iter!(evals).any(|eval| *eval != B::F::zero()) {
                tracing::error!("The emitted Zerocheck claim is false");
                return Err(ProverError(HonestProverError(FalseClaim)));
            }
        }
        self.state
            .mv_pcs_substate
            .zero_check_claims
            .push(TrackerZerocheckClaim::new(poly_id));
        Ok(())
    }

    /// Adds a nozerocheck claim to the list of the nozerocheck claims of the prover
    /// a nozerocheck claim is of the form (poly_id) which means that the prover
    /// claims that the polynomial with poly_id evaluates to zero all over the
    /// boolean hypercube
    pub fn add_mv_nozerocheck_claim(&mut self, poly_id: TrackerID) -> SnarkResult<()> {
        if let Some(poly) = self.virt_poly(poly_id) {
            trace!(?poly_id, ?poly, "add_mv_nozerocheck_claim virtual");
        } else {
            trace!(?poly_id, "add_mv_nozerocheck_claim materialized");
        }
        #[cfg(feature = "honest-prover")]
        {
            let evals = self.evaluations(poly_id);
            if cfg_iter!(evals).any(|eval| *eval == B::F::zero()) {
                tracing::error!("error");
                return Err(ProverError(HonestProverError(FalseClaim)));
            }
        }
        self.state
            .mv_pcs_substate
            .no_zero_check_claims
            .push(TrackerNoZerocheckClaim::new(poly_id));
        Ok(())
    }

    /// Add a multivariate lookup claim to the proof
    #[instrument(level = "debug", skip(self))]
    pub fn add_mv_lookup_claim(
        &mut self,
        super_id: TrackerID,
        sub_id: TrackerID,
    ) -> SnarkResult<()> {
        #[cfg(feature = "honest-prover")]
        {
            let super_evals = self.evaluations(super_id);
            let sub_evals = self.evaluations(sub_id);
            let super_eval_set: HashSet<B::F> = super_evals.into_iter().collect();
            if cfg_iter!(sub_evals).any(|eval| !super_eval_set.contains(eval)) {
                tracing::error!("error");
                return Err(ProverError(HonestProverError(FalseClaim)));
            }
        }
        self.state
            .mv_pcs_substate
            .lookup_claims
            .push(TrackerLookupClaim::new(super_id, sub_id));
        Ok(())
    }

    pub(crate) fn take_lookup_claims(&mut self) -> Vec<TrackerLookupClaim> {
        take(&mut self.state.mv_pcs_substate.lookup_claims)
    }

    /// Adds an evaluation claim to the list of the zerocheck claims of the
    /// prover a zerocheck claim is of the form (poly_id) which means that
    /// the prover claims that the polynomial with poly_id evaluates to zero
    /// all over the boolean hypercube
    pub fn add_uv_eval_claim(&mut self, poly_id: TrackerID, point: B::F) -> SnarkResult<()> {
        self.state
            .uv_pcs_substate
            .eval_claims
            .push(TrackerEvalClaim::new(poly_id, point));
        Ok(())
    }

    pub fn insert_miscellaneous_field(&mut self, key: String, field: B::F) {
        self.state.miscellaneous_field_elements.insert(key, field);
    }

    pub fn add_mv_eval_claim(&mut self, poly_id: TrackerID, point: &[B::F]) -> SnarkResult<()> {
        self.state
            .mv_pcs_substate
            .eval_claims
            .push(TrackerEvalClaim::new(poly_id, point.to_vec()));
        Ok(())
    }

    // TODO: Is this only used to be compatible with the hyperplonk code?
    #[instrument(level = "debug", skip_all)]
    pub(crate) fn to_hp_virtual_poly(&self, id: TrackerID) -> HPVirtualPolynomial<B::F> {
        let mat_poly = self.state.mv_pcs_substate.materialized_polys.get(&id);
        if let Some(poly) = mat_poly {
            return HPVirtualPolynomial::new_from_mle(poly, B::F::one());
        }

        let poly = self.state.virtual_polys.get(&id);
        if poly.is_none() {
            panic!("Unknown poly id: {:?}", id);
        }
        let poly = poly.unwrap(); // Invariant: contains only material PolyIDs
        if poly.is_empty() {
            return HPVirtualPolynomial::new(1);
        }
        let first_id = poly[0].1[0];
        let nv: usize = self.mat_mv_poly(first_id).unwrap().num_vars();

        let mut arith_virt_poly: HPVirtualPolynomial<B::F> = HPVirtualPolynomial::new(nv);
        for (prod_coef, prod) in poly.iter() {
            let prod_mle_list = prod
                .iter()
                .map(|poly_id| self.mat_mv_poly(*poly_id).unwrap().clone())
                .collect::<Vec<Arc<MLE<B::F>>>>();
            arith_virt_poly
                .add_mle_list(prod_mle_list, *prod_coef)
                .unwrap();
        }

        arith_virt_poly
    }

    /// Iterates through the materialized polynomials and increases the number
    /// of variables to the max number of variables in the tracker
    /// Used as a preprocessing step before batching polynomials,
    // TODO: This can be potentially reduced
    #[instrument(level = "debug", skip(self))]
    fn equalize_mat_poly_nv(&mut self) -> usize {
        // calculate the max nv
        let max_nv = self.state.num_vars.values().max().copied().unwrap_or(0);

        for poly in self.state.mv_pcs_substate.materialized_polys.values_mut() {
            let old_nv = poly.num_vars();
            if old_nv != max_nv {
                let inner_poly = Arc::get_mut(poly).unwrap();
                let inner = std::mem::take(inner_poly.mat_mle_mut());
                *poly = Arc::new(MLE::new(inner, Some(max_nv)));
            }
        }

        for claim in &mut self.state.mv_pcs_substate.sum_check_claims {
            let nv = self.state.num_vars[&claim.id()];
            claim.set_claim(claim.claim() * B::F::from(1 << (max_nv - nv)))
        }

        for claim in self.state.mv_pcs_substate.eval_claims.iter_mut() {
            let mut point = claim.point().clone();
            point.resize(max_nv, B::F::zero());
            claim.set_point(point);
        }
        max_nv
    }

    /// converts all the zerocheck claims into a single zero claim
    /// technique: If p1=0, ..., pn=0, then c1*p1 + ... + cn*pn = 0 where ci-s
    /// are random. At the end of this function, there should only be one
    /// zerocheck claim in the prover state.
    #[instrument(level = "debug", skip(self))]
    fn batch_z_check_claims(&mut self) -> SnarkResult<()> {
        debug!(
            "Zerocheck claims with degrees: {}",
            self.state
                .mv_pcs_substate
                .zero_check_claims
                .iter()
                .map(|claim| self.virt_poly_degree(claim.id()))
                .collect::<Vec<usize>>()
                .iter()
                .map(|d| d.to_string())
                .collect::<Vec<String>>()
                .join(", ")
        );
        let num_claims = self.state.mv_pcs_substate.zero_check_claims.len();

        if num_claims == 0 {
            debug!("No zerocheck claims to batch",);
            return Ok(());
        }

        // build the running aggregate polynomial
        let mut agg = self.track_virt_poly(VirtualPoly::new());
        // Perform the random linear combination and aggregate them
        agg = take(&mut self.state.mv_pcs_substate.zero_check_claims)
            .into_iter()
            .fold(agg, |acc, claim| {
                let ch = self
                    .get_and_append_challenge(b"zerocheck challenge")
                    .unwrap();
                let cp = self.mul_scalar(claim.id(), ch);
                self.add_polys(acc, cp)
            });

        // Push the new aggregated claim to the prover state as the inly zerocheck claim
        self.add_mv_zerocheck_claim(agg)?;
        debug!(
            "{} zerocheck claims were batched into 1 zerocheck claim with degree {}",
            num_claims,
            self.virt_poly_degree(agg)
        );
        Ok(())
    }

    // Aggregate the sumcheck claims, instead of proving p_1 = s_1, p_2 = s_2, ...
    // p_n = s_n, we prove c_1 * p_1 + c_2 * p_2 + ... + c_n * p_n = c_1 *
    // s_1 + c_2 * s_2 + ... + c_n * s_n where c_i-s are random challenges
    #[instrument(level = "debug", skip(self))]
    fn batch_s_check_claims(&mut self) -> SnarkResult<BTreeMap<TrackerID, B::F>> {
        let num_claims = self.state.mv_pcs_substate.sum_check_claims.len();

        if num_claims == 0 {
            debug!("No sumcheck claims to batch",);
            return Ok(BTreeMap::new());
        }

        let mut agg = self.track_virt_poly(VirtualPoly::new());
        let mut sc_sum = B::F::zero();

        // Record the individual sumcheck claims to send to the verifier
        //TODO: This is only recorded for a specific protocol that uses this library and needs these, i.e. multiplicity-check. This should be removed from the library and added to the user-defined optional proof elements.
        let individual_sumcheck_claims: BTreeMap<TrackerID, B::F> = self
            .state
            .mv_pcs_substate
            .sum_check_claims
            .iter()
            .map(|claim| (claim.id(), claim.claim()))
            .collect();

        // Perform the random linear combination and aggregate them
        agg = take(&mut self.state.mv_pcs_substate.sum_check_claims)
            .into_iter()
            .fold(agg, |acc, claim| {
                let ch = self
                    .get_and_append_challenge(b"sumcheck challenge")
                    .unwrap();
                let cp = self.mul_scalar(claim.id(), ch);
                sc_sum += claim.claim() * ch;
                self.add_polys(acc, cp)
            });
        // Now the sumcheck claims are empty
        // Add the new aggregated sumcheck claim to the list of claims
        self.add_mv_sumcheck_claim(agg, sc_sum)?;
        debug!(
            "{} sumcheck claims were batched into 1 sumcheck claim",
            num_claims
        );
        Ok(individual_sumcheck_claims)
    }

    /// Convert the zerocheck claim to a sumcheck claim
    /// Note that at this point, there is only one batched
    /// zero-check
    /// Technique: Run a sumcheck over f'(X) = f(X) * eq(X, r) for a random
    /// challenge r
    #[instrument(level = "debug", skip(self))]
    fn z_check_claim_to_s_check_claim(&mut self, max_nv: usize) -> SnarkResult<()> {
        if self.state.mv_pcs_substate.zero_check_claims.is_empty() {
            debug!("No zerocheck claims to convert to sumcheck claims",);
            return Ok(());
        }
        // Check at this point there should be only one batched zero check claim
        debug_assert_eq!(self.state.mv_pcs_substate.zero_check_claims.len(), 1);
        // sample the random challenge r
        let r = self
            .state
            .transcript
            .get_and_append_challenge_vectors(b"0check r", max_nv)
            .unwrap();
        // Get the zero check claim polynomial id
        let z_check_aggr_id = self
            .state
            .mv_pcs_substate
            .zero_check_claims
            .last()
            .unwrap()
            .id();

        // build the eq(x, r) polynomial
        let eq_x_r_id = self.track_mat_arc_mv_poly(build_eq_x_r(r.as_ref()).unwrap());

        // create the relevant sumcheck claim, i.e. reduce the zerocheck claim to a
        // sumcheck claim
        let new_sc_claim_poly = self.mul_polys(z_check_aggr_id, eq_x_r_id);

        // Add this new sumcheck claim to other sumcheck claims
        self.add_mv_sumcheck_claim(new_sc_claim_poly, B::F::zero())?;
        // Clear the zerocheck claim: it has been converted into a sumcheck claim.
        self.state.mv_pcs_substate.zero_check_claims.clear();
        debug!(
            "The only zerocheck claim was converted to a sumcheck claim with degree {}",
            self.virt_poly_degree(new_sc_claim_poly)
        );
        Ok(())
    }

    #[instrument(level = "debug", skip(self))]
    fn perform_single_sumcheck(&mut self) -> SnarkResult<(SumcheckProof<B::F>, VPAuxInfo<B::F>)> {
        assert!(self.state.mv_pcs_substate.sum_check_claims.len() == 1);

        // Get the sumcheck claim polynomial id
        let sumcheck_aggr_id = self
            .state
            .mv_pcs_substate
            .sum_check_claims
            .last()
            .unwrap()
            .id();
        // Generate a sumcheck proof

        let sc_avp = self.to_hp_virtual_poly(sumcheck_aggr_id);
        debug!(
            "The final virtual polynomial for sumcheck has {} terms, {} degree, and {} number of variables",
            sc_avp.products.len(),
            sc_avp.aux_info.max_degree,
            sc_avp.aux_info.num_variables
        );
        let sc_aux_info = sc_avp.aux_info.clone();
        let sc_proof = SumCheck::prove(&sc_avp, &mut self.state.transcript)?;
        let _ = self.add_mv_eval_claim(sumcheck_aggr_id, &sc_proof.point);
        Ok((sc_proof, sc_aux_info))
    }

    /// Reduce high-degree product terms in the single aggregated sumcheck polynomial.
    ///
    /// Deterministic two-pass reduction:
    /// 1) Factor-aware contraction: if a term references a virtual polynomial
    ///    directly, commit that virtual polynomial and replace its id. This
    ///    preserves factorized structure when present (e.g., (a1+b1)(a2+b2)).
    /// 2) Reuse-first chunking on remaining oversized terms (flattened factors).
    ///
    /// This keeps the process deterministic, fast, and in sync with the verifier.
    fn reduce_sumcheck_dgree(&mut self) -> SnarkResult<()> {
        const MAX_TERM_DEGREE: usize = crate::SUMCHECK_TERM_DEGREE_LIMIT;

        debug_assert!(
            self.state.mv_pcs_substate.zero_check_claims.is_empty(),
            "reduce_sumcheck_dgree expects no zerocheck claims"
        );
        debug_assert_eq!(
            self.state.mv_pcs_substate.sum_check_claims.len(),
            1,
            "reduce_sumcheck_dgree expects exactly one sumcheck claim"
        );

        let mut cache: BTreeMap<Vec<TrackerID>, TrackerID> = BTreeMap::new();
        let mut extra_zero_claims: Vec<TrackerID> = Vec::new();
        let mut committed_chunks: usize = 0;
        let mut oversized_terms_reduced: usize = 0;
        let mut claims_reduced: usize = 0;
        let mut total_terms: usize = 0;

        fn reduce_poly<B: SnarkBackend>(
            tracker: &mut ProverTracker<B>,
            poly_id: TrackerID,
            cache: &mut BTreeMap<Vec<TrackerID>, TrackerID>,
            extra_zero_claims: &mut Vec<TrackerID>,
            committed_chunks: &mut usize,
            oversized_terms_reduced: &mut usize,
        ) -> SnarkResult<TrackerID> {
            if tracker.mat_mv_poly(poly_id).is_some() {
                return Ok(poly_id);
            }
            let virt_poly = match tracker.virt_poly(poly_id) {
                Some(poly) => poly.clone(),
                None => return Ok(poly_id),
            };
            let mut term_ids: Vec<Vec<TrackerID>> =
                virt_poly.iter().map(|(_, ids)| ids.clone()).collect();
            for ids in term_ids.iter_mut() {
                ids.sort();
            }
            let claim_term_count = term_ids.len();
            let claim_oversized = term_ids
                .iter()
                .filter(|ids| ids.len() > MAX_TERM_DEGREE)
                .count();
            let claim_max_degree = term_ids.iter().map(|ids| ids.len()).max().unwrap_or(0);
            *oversized_terms_reduced += claim_oversized;
            debug!(
                claim_id = ?poly_id,
                claim_term_count,
                claim_oversized,
                claim_max_degree,
                "sumcheck degree reduction claim stats"
            );

            // Pass 1: factor-aware contraction of virtual subpolys referenced in terms.
            let mut virtual_ids: BTreeSet<TrackerID> = BTreeSet::new();
            for ids in term_ids.iter() {
                for id in ids.iter() {
                    if tracker.mat_mv_poly(*id).is_none() {
                        virtual_ids.insert(*id);
                    }
                }
            }
            for vid in virtual_ids.into_iter() {
                // Only contract if the virtual poly is directly materializable
                // (i.e., it is a sum of products of material polys).
                let Some(vpoly) = tracker.virt_poly(vid) else {
                    continue;
                };
                let is_material_only = vpoly
                    .iter()
                    .all(|(_, ids)| ids.iter().all(|id| tracker.mat_mv_poly(*id).is_some()));
                if !is_material_only {
                    continue;
                }
                if cache.contains_key(&vec![vid]) {
                    continue;
                }
                // Materialize the virtual poly, commit it, and add zerocheck diff.
                let mat = tracker.materialize_poly(vid);
                let committed_id = tracker.track_and_commit_mat_mv_p(mat.as_ref())?;
                cache.insert(vec![vid], committed_id);
                let neg_committed = tracker.mul_scalar(committed_id, -B::F::one());
                let diff_id = tracker.add_polys(vid, neg_committed);
                extra_zero_claims.push(diff_id);
                // Replace occurrences in term_ids.
                for ids in term_ids.iter_mut() {
                    for id in ids.iter_mut() {
                        if *id == vid {
                            *id = committed_id;
                        }
                    }
                    ids.sort();
                }
            }

            // Pass 2: Build a global frequency map of size-MAX_TERM_DEGREE chunks across oversized terms.
            let mut freq: BTreeMap<Vec<TrackerID>, usize> = BTreeMap::new();
            for ids in term_ids.iter() {
                if ids.len() <= MAX_TERM_DEGREE {
                    continue;
                }
                for window in ids.windows(MAX_TERM_DEGREE) {
                    let key = window.to_vec();
                    *freq.entry(key).or_insert(0) += 1;
                }
            }

            // Order candidates by descending frequency, then lexicographic order.
            let mut candidates: Vec<(Vec<TrackerID>, usize)> = freq.into_iter().collect();
            candidates.sort_by(|(a_ids, a_cnt), (b_ids, b_cnt)| {
                b_cnt.cmp(a_cnt).then_with(|| a_ids.cmp(b_ids))
            });

            // Helper: find the first candidate chunk that is a subset of `ids`.
            fn find_best_chunk(
                ids: &[TrackerID],
                candidates: &[(Vec<TrackerID>, usize)],
            ) -> Option<Vec<TrackerID>> {
                for (chunk, _) in candidates.iter() {
                    // Two-pointer subset check (both sorted).
                    let mut i = 0usize;
                    let mut j = 0usize;
                    while i < ids.len() && j < chunk.len() {
                        if ids[i] == chunk[j] {
                            i += 1;
                            j += 1;
                        } else if ids[i] < chunk[j] {
                            i += 1;
                        } else {
                            break;
                        }
                    }
                    if j == chunk.len() {
                        return Some(chunk.clone());
                    }
                }
                None
            }

            // Helper: remove the first occurrence of each element in `chunk` from `ids`.
            fn remove_chunk(ids: &mut Vec<TrackerID>, chunk: &[TrackerID]) {
                let mut write = 0usize;
                let mut j = 0usize;
                for i in 0..ids.len() {
                    if j < chunk.len() && ids[i] == chunk[j] {
                        j += 1;
                    } else {
                        ids[write] = ids[i];
                        write += 1;
                    }
                }
                ids.truncate(write);
            }

            // Commit a chunk (if needed) and register its zerocheck constraint.
            fn commit_chunk<B: SnarkBackend>(
                tracker: &mut ProverTracker<B>,
                chunk: &[TrackerID],
                cache: &mut BTreeMap<Vec<TrackerID>, TrackerID>,
                extra_zero_claims: &mut Vec<TrackerID>,
                committed_chunks: &mut usize,
            ) -> SnarkResult<TrackerID> {
                if let Some(id) = cache.get(chunk).copied() {
                    return Ok(id);
                }

                // Materialize product evaluations for the chunk.
                let nv = tracker.mat_mv_poly(chunk[0]).unwrap().num_vars();
                let mut evals = vec![B::F::one(); 1 << nv];
                for id in chunk {
                    let poly = tracker.mat_mv_poly(*id).unwrap();
                    cfg_iter_mut!(evals)
                        .zip(poly.evaluations())
                        .for_each(|(a, b)| *a *= b);
                }
                let mle = Arc::new(MLE::from_evaluations_vec(nv, evals));

                // Commit deterministically and track the commitment.
                let prover_param = tracker.pk.mv_pcs_param.clone();
                let com = B::MvPCS::commit(prover_param.as_ref(), &mle)?;
                let committed_id = tracker.track_mat_mv_p_and_commitment(&mle, com)?;
                cache.insert(chunk.to_vec(), committed_id);
                *committed_chunks += 1;

                // Add zerocheck: committed - product(chunk) == 0.
                let mut chunk_poly = VirtualPoly::new();
                chunk_poly.push((B::F::one(), chunk.to_vec()));
                let chunk_id = tracker.track_virt_poly(chunk_poly);
                let neg_committed = tracker.mul_scalar(committed_id, -B::F::one());
                let diff_id = tracker.add_polys(chunk_id, neg_committed);
                extra_zero_claims.push(diff_id);

                Ok(committed_id)
            }

            // Greedily reduce each term using globally frequent chunks.
            for ids in term_ids.iter_mut() {
                while ids.len() > MAX_TERM_DEGREE {
                    // Pick the most frequent matching chunk; otherwise fallback to the
                    // lexicographically smallest size-MAX chunk from this term.
                    let chunk = find_best_chunk(ids, &candidates)
                        .or_else(|| ids.get(..MAX_TERM_DEGREE).map(|s| s.to_vec()))
                        .expect("term must be non-empty");

                    let committed_id =
                        commit_chunk(tracker, &chunk, cache, extra_zero_claims, committed_chunks)?;
                    remove_chunk(ids, &chunk);
                    let insert_at = ids.binary_search(&committed_id).unwrap_or_else(|i| i);
                    ids.insert(insert_at, committed_id);
                }
            }

            let mut new_poly = VirtualPoly::new();
            for ((coeff, _old_ids), ids) in virt_poly.iter().zip(term_ids.into_iter()) {
                new_poly.push((*coeff, ids));
            }
            let new_id = tracker.track_virt_poly(new_poly);
            Ok(new_id)
        }

        let reduce_span = tracing::debug_span!("reduce_sumcheck_degree");
        let _reduce_guard = reduce_span.enter();

        let sum_claims = take(&mut self.state.mv_pcs_substate.sum_check_claims);
        for claim in sum_claims.into_iter() {
            claims_reduced += 1;
            let new_id = reduce_poly(
                self,
                claim.id(),
                &mut cache,
                &mut extra_zero_claims,
                &mut committed_chunks,
                &mut oversized_terms_reduced,
            )?;
            self.state
                .mv_pcs_substate
                .sum_check_claims
                .push(TrackerSumcheckClaim::new(new_id, claim.claim()));
            if let Some(vpoly) = self.virt_poly(new_id) {
                total_terms += vpoly.len();
            }
        }

        let extra_zero_claims_len = extra_zero_claims.len();
        for id in extra_zero_claims {
            self.add_mv_zerocheck_claim(id)?;
        }

        debug!(
            committed_chunks,
            extra_zerochecks_added = extra_zero_claims_len,
            oversized_terms_reduced,
            claims_reduced,
            total_terms,
            "sumcheck degree reduction stats"
        );

        Ok(())
    }

    #[instrument(level = "debug", skip(self))]
    fn batch_nozero_check_claims(&mut self) -> SnarkResult<()> {
        const NOZERO_CHUNK_SIZE: usize = 1;
        let nozero_claims = take(&mut self.state.mv_pcs_substate.no_zero_check_claims);
        if nozero_claims.is_empty() {
            return Ok(());
        }

        // Use the largest nv in the tracker so all committed chunk polys share a domain.
        let max_nv = self.state.num_vars.values().max().copied().unwrap_or(0);
        let num_claims = nozero_claims.len();
        let mut chunk_comm_ids = Vec::new(); // committed chunk products (materialized)
        let mut master_prod_id = None; // virtual product of chunk commitments
        let mut master_evals: Option<Vec<B::F>> = None; // evals of the same product

        for chunk in nozero_claims.chunks(NOZERO_CHUNK_SIZE) {
            let mut iter = chunk.iter();
            let first = iter
                .next()
                .expect("nozero_claims chunk should be non-empty");
            // 1) Multiply polynomials in the chunk (virtual product + evals).
            let mut chunk_prod_id = first.id();
            let mut chunk_evals = self.evaluations(first.id());
            for claim in iter {
                let id = claim.id();
                chunk_prod_id = self.mul_polys(chunk_prod_id, id);
                let evals = self.evaluations(id);
                debug_assert_eq!(chunk_evals.len(), evals.len());
                cfg_iter_mut!(chunk_evals)
                    .zip(evals)
                    .for_each(|(a, b)| *a *= b);
            }

            // 2) Expand evals to max_nv (by repetition) and commit to the chunk product.
            let base_len = chunk_evals.len();
            debug_assert!(base_len.is_power_of_two());
            let base_nv = base_len.trailing_zeros() as usize;
            if base_nv < max_nv {
                let expand = 1usize << (max_nv - base_nv);
                let mut expanded = Vec::with_capacity(base_len * expand);
                for v in &chunk_evals {
                    expanded.extend(std::iter::repeat(*v).take(expand));
                }
                chunk_evals = expanded;
            }
            let chunk_mle = MLE::from_evaluations_vec(max_nv, chunk_evals.clone());
            let chunk_comm_id = self.track_and_commit_mat_mv_p(&chunk_mle)?;
            // Link committed chunk to its virtual definition: c_i - prod_i == 0.
            let diff_id = self.sub_polys(chunk_comm_id, chunk_prod_id);
            self.add_mv_zerocheck_claim(diff_id)?;

            // 3) Accumulate committed chunks into a master product (virtual + evals).
            master_prod_id = Some(match master_prod_id {
                None => chunk_comm_id,
                Some(acc) => self.mul_polys(acc, chunk_comm_id),
            });
            master_evals = Some(match master_evals {
                None => chunk_evals,
                Some(mut acc) => {
                    debug_assert_eq!(acc.len(), chunk_evals.len());
                    cfg_iter_mut!(acc)
                        .zip(chunk_evals)
                        .for_each(|(a, b)| *a *= b);
                    acc
                }
            });
            chunk_comm_ids.push(chunk_comm_id);
        }

        let master_prod_id = master_prod_id.expect("nozero_claims should be non-empty");
        let mut master_evals = master_evals.expect("nozero_claims should be non-empty");

        debug!(
            "{} nozerocheck polynomials chunked into {}; final degree {}",
            num_claims,
            chunk_comm_ids.len(),
            self.virt_poly_degree(master_prod_id)
        );

        // 4) Commit to the inverse of the master product and enforce prod * inv == 1.
        batch_inversion(&mut master_evals);
        let inverses_mle = MLE::from_evaluations_vec(max_nv, master_evals);
        let inverses_poly_id = self.track_and_commit_mat_mv_p(&inverses_mle)?;

        let prod_inv_id = self.mul_polys(master_prod_id, inverses_poly_id);
        let diff_id = self.add_scalar(prod_inv_id, -B::F::one());
        self.add_mv_zerocheck_claim(diff_id)?;

        Ok(())
    }

    /// Reduces every zero-check claim, sum-check claim in
    /// the prover state, into a list of evaluation claims. These evaluation
    /// claims will be proved using a PCS
    #[instrument(level = "debug", skip(self))]
    fn compile_sc_subproof(
        &mut self,
        max_nv: usize,
    ) -> SnarkResult<Option<SumcheckSubproof<B::F>>> {
        self.batch_nozero_check_claims()?;
        // Batch all the zero-check claims into one claim, remove old zerocheck claims
        self.batch_z_check_claims()?;
        // Convert the only zerocheck claim to a sumcheck claim
        self.z_check_claim_to_s_check_claim(max_nv)?;
        // Batch all the sumcheck claims into one sumcheck claim
        let mut individual_sumcheck_claims = self.batch_s_check_claims()?;
        if self.state.mv_pcs_substate.sum_check_claims.is_empty() {
            debug!("No sumcheck claims to prove",);
            return Ok(None);
        }

        // Reduce high-degree terms deterministically before sumcheck.
        self.reduce_sumcheck_dgree()?;

        // Batch all the zero-check claims into one claim, remove old zerocheck claims
        self.batch_z_check_claims()?;
        // Convert the only zerocheck claim to a sumcheck claim
        self.z_check_claim_to_s_check_claim(max_nv)?;
        // Batch all the sumcheck claims into one sumcheck claim
        let additional_sumcheck_claims = self.batch_s_check_claims()?;
        for (id, claim) in additional_sumcheck_claims {
            individual_sumcheck_claims.entry(id).or_insert(claim);
        }
        // if self.state.mv_pcs_substate.sum_check_claims.is_empty() {
        //     debug!("No sumcheck claims to prove",);
        //     return Ok(None);
        // }
        // Perform the one batched sumcheck
        let (sc_proof, sc_aux_info) = self.perform_single_sumcheck()?;
        // Assemble the sumcheck subproof of the prover
        let sc_subproof = SumcheckSubproof::new(
            sc_proof.clone(),
            sc_aux_info.clone(),
            individual_sumcheck_claims,
        );
        Ok(Some(sc_subproof))
    }

    /// Compiles the PCS subproof, a proof containg (a) a list of comitments to
    /// the polynomials that the verifier needs oracle access to (b) a query
    /// map, which is the list of all the possible verifier queries to these
    /// comitments (c) a batch opening proof corresponding to the query map
    #[instrument(level = "debug", skip(self))]
    pub fn compile_mv_pcs_subproof(&mut self) -> SnarkResult<PCSSubproof<B::F, B::MvPCS>> {
        let mut query_map: BTreeMap<(TrackerID, Vec<B::F>), B::F> = BTreeMap::new();
        let mut mat_polys = Vec::new();
        let mut points = Vec::new();
        let mut evals = Vec::new();
        for claim in &self.state.mv_pcs_substate.eval_claims {
            let eval_id = claim.id();
            let eval_point = claim.point();
            let mat_ids = self.extract_mv_openable_ids(eval_id);
            for mat_id in mat_ids {
                let eval = self.evaluate_mv(mat_id, eval_point).unwrap();
                query_map.insert((mat_id, eval_point.clone()), eval);
                mat_polys.push(self.mat_mv_poly(mat_id).unwrap().clone());
                points.push(eval_point.clone());
                evals.push(eval);
            }
        }

        let opening_proof: PCSOpeningProof<B::F, B::MvPCS>;
        if mat_polys.len() == 1 {
            let single_proof = B::MvPCS::open(
                self.pk.mv_pcs_param.as_ref(),
                &mat_polys[0],
                &points[0],
                None,
            )?;
            opening_proof = PCSOpeningProof::SingleProof(single_proof.0);
            assert!(single_proof.1 == evals[0]);
        } else if mat_polys.len() > 1 {
            let batch_proof = B::MvPCS::multi_open(
                self.pk.mv_pcs_param.as_ref(),
                &mat_polys,
                &points,
                &evals,
                &mut self.state.transcript,
            )?;
            opening_proof = PCSOpeningProof::BatchProof(batch_proof);
        } else {
            opening_proof = PCSOpeningProof::Empty;
        }

        // Perform the batch-opening

        Ok(PCSSubproof {
            query_map,
            opening_proof,
            comitments: self.state.mv_pcs_substate.materialized_comms.clone(),
        })
    }

    /// Compiles the PCS subproof, a proof containg (a) a list of comitments to
    /// the polynomials that the verifier needs oracle access to (b) a query
    /// map, which is the list of all the possible verifier queries to these
    /// comitments (c) a batch opening proof corresponding to the query map
    #[instrument(level = "debug", skip(self))]
    pub fn compile_uv_pcs_subproof(&mut self) -> SnarkResult<PCSSubproof<B::F, B::UvPCS>> {
        let mut query_map: BTreeMap<(TrackerID, B::F), B::F> = BTreeMap::new();
        let mut mat_polys = Vec::new();
        let mut points = Vec::new();
        let mut evals = Vec::new();
        for claim in &self.state.uv_pcs_substate.eval_claims {
            let eval_id = claim.id();
            let eval_point = claim.point();
            let mat_ids = self.extract_uv_openable_ids(eval_id);
            for mat_id in mat_ids {
                let eval = self.evaluate_uv(mat_id, eval_point).unwrap();
                query_map.insert((mat_id, *eval_point), eval);
                mat_polys.push(self.mat_uv_poly(mat_id).unwrap().clone());
                points.push(*eval_point);
                evals.push(eval);
            }
        }

        let opening_proof: PCSOpeningProof<B::F, B::UvPCS>;
        if mat_polys.len() == 1 {
            let single_proof = B::UvPCS::open(
                self.pk.uv_pcs_param.as_ref(),
                &mat_polys[0],
                &points[0],
                None,
            )?;
            opening_proof = PCSOpeningProof::SingleProof(single_proof.0);
            assert!(single_proof.1 == evals[0]);
        } else if mat_polys.len() > 1 {
            let batch_proof = B::UvPCS::multi_open(
                self.pk.uv_pcs_param.as_ref(),
                &mat_polys,
                &points,
                &evals,
                &mut self.state.transcript,
            )?;
            opening_proof = PCSOpeningProof::BatchProof(batch_proof);
        } else {
            opening_proof = PCSOpeningProof::Empty;
        }

        // Perform the batch-opening

        Ok(PCSSubproof {
            query_map,
            opening_proof,
            comitments: self.state.uv_pcs_substate.materialized_comms.clone(),
        })
    }

    /// Compiled the final proof, which contains three subproofs:
    /// 1. The batched sumcheck subproof
    /// 2. The multivariate PCS subproof
    /// 3. The univariate PCS subproof
    #[instrument(level = "debug", skip(self))]
    pub fn compile_proof(&mut self) -> SnarkResult<SNARKProof<B>>
    where
        B: SnarkBackend,
    {
        // Transform all the materialized polynomials to polynomials with the maximum
        // number of variables needed
        let max_nv = self.equalize_mat_poly_nv();
        // Assemble and output the final proof
        let proof = SNARKProof {
            sc_subproof: self.compile_sc_subproof(max_nv)?,
            mv_pcs_subproof: self.compile_mv_pcs_subproof()?,
            uv_pcs_subproof: self.compile_uv_pcs_subproof()?,
            miscellaneous_field_elements: self.state.miscellaneous_field_elements.clone(),
        };
        self.state.miscellaneous_field_elements.clear();
        Ok(proof)
    }
}
