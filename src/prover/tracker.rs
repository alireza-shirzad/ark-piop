use super::structs::{
    ProcessedSNARKPk, ProverState,
    proof::{PCSSubproof, SNARKProof},
};
use crate::{
    SnarkBackend,
    structs::claim::{TrackerLookupClaim, TrackerNoZerocheckClaim},
};
use crate::{
    arithmetic::mat_poly::utils::evaluate_with_eq, prover::tracker::SnarkError::ProverError,
};
use crate::{
    arithmetic::{
        mat_poly::{lde::LDE, mle::MLE, utils::build_eq_x_r},
        virt_poly::{
            VirtualPoly,
            hp_interface::{HPVirtualPolynomial, VPAuxInfo},
        },
    },
    errors::{SnarkError, SnarkResult},
    pcs::PCS,
    piop::{structs::SumcheckProof, sum_check::SumCheck},
    setup::{
        errors::SetupError::NoRangePoly,
        structs::{SNARKPk, SNARKVk},
    },
    structs::{
        PCSOpeningProof, PointID, SumcheckSubproof, TrackerID,
        claim::{TrackerSumcheckClaim, TrackerZerocheckClaim},
    },
};
use crate::{
    prover::{errors::HonestProverError::FalseClaim, structs::TrackerEvalClaim},
    prover::{errors::ProverError::HonestProverError, structs::polynomial::TrackedPoly},
};
use ark_ec::AdditiveGroup;
use ark_ff::batch_inversion;
use ark_poly::Polynomial;
use ark_std::One;
use ark_std::Zero;
use ark_std::{cfg_iter, cfg_iter_mut};
use derivative::Derivative;
use either::Either;

#[cfg(feature = "parallel")]
use rayon::prelude::*;
use std::{
    cell::RefCell,
    collections::{BTreeMap, BTreeSet, HashMap, HashSet},
    mem::take,
    panic,
    rc::Rc,
    rc::Weak,
    sync::Arc,
};
use tracing::{debug, instrument, trace};
/// The Tracker is a data structure for creating and managing virtual
/// polynomials and their comitments. It is in charge of  
///  1) Recording the structure of virtual polynomials and
///     their products
///  2) Recording the structure of virtual polynomials and
///     their products
///  3) Recording the comitments of virtual polynomials and
///     their products
///  4) Providing methods for adding virtual polynomials
///     together

// Clone is only implemented if PCS satisfies the PCS<F>
// bound, which guarantees that PCS::ProverParam
#[derive(Derivative)]
#[derivative(Clone(bound = ""))]
// #[derivative(Clone(bound = "MvPCS: Clone, UvPCS: Clone"))]
pub struct ProverTracker<B>
where
    B: SnarkBackend,
{
    pub pk: ProcessedSNARKPk<B>,
    pub state: ProverState<B>,
    self_rc: Option<Weak<RefCell<ProverTracker<B>>>>,
}

impl<B> ProverTracker<B>
where
    B: SnarkBackend,
{
    pub fn new_from_pk(pk: SNARKPk<B>) -> Self {
        let mut tracker = Self {
            pk: ProcessedSNARKPk::new_from_pk(&pk),
            state: ProverState::default(),
            self_rc: None,
        };
        tracker.add_vk_to_transcript(pk.vk.clone());
        tracker
    }

    pub fn set_self_rc(&mut self, self_rc: Weak<RefCell<ProverTracker<B>>>) {
        self.self_rc = Some(self_rc);
    }

    fn add_vk_to_transcript(&mut self, vk: SNARKVk<B>) {
        self.state
            .transcript
            .append_serializable_element(b"vk", &vk)
            .unwrap();
        vk.indexed_coms.iter().for_each(|(_, comm)| {
            self.state
                .transcript
                .append_serializable_element(b"comm", comm)
                .unwrap();
        });
    }

    pub(crate) fn set_indexed_tracked_polys(
        &mut self,
        range_tr_polys: BTreeMap<String, TrackedPoly<B>>,
    ) {
        self.state.indexed_tracked_polys = range_tr_polys;
    }

    /// Get the range tracked polynomial given the data type
    pub fn indexed_tracked_poly(&self, label: String) -> SnarkResult<TrackedPoly<B>> {
        match self.state.indexed_tracked_polys.get(&label) {
            Some(poly) => Ok(poly.clone()),
            _ => Err(SnarkError::SetupError(NoRangePoly(format!("{:?}", label)))),
        }
    }

    pub fn add_indexed_tracked_poly(
        &mut self,
        label: String,
        poly: TrackedPoly<B>,
    ) -> Option<TrackedPoly<B>> {
        self.state.indexed_tracked_polys.insert(label, poly)
    }

    /// Generates a new `TrackerID`.
    ///
    /// This function increments an internal counter and returns a new
    /// `TrackerID` based on the current value of the counter. It ensures
    /// that each generated `TrackerID` is unique.
    pub fn gen_id(&mut self) -> TrackerID {
        let id = self.state.num_tracked_polys;
        self.state.num_tracked_polys += 1;
        TrackerID::from_usize(id)
    }

    /// Peek at the next `TrackerID` that will be generated by gen_id.
    pub fn next_id(&mut self) -> TrackerID {
        TrackerID::from_usize(self.state.num_tracked_polys)
    }

    // Peek at the next TrackerID without incrementing the counter
    pub(crate) fn peek_next_id(&mut self) -> TrackerID {
        TrackerID::from_usize(self.state.num_tracked_polys)
    }

    /// Tracks a materialized polynomial.
    ///
    /// moves the polynomial to heap, assigns a TracckerID to it in map and
    /// returns the TrackerID
    pub fn track_mat_mv_poly(&mut self, polynomial: MLE<B::F>) -> TrackerID {
        let polynomial = Arc::new(polynomial);
        self.track_mat_arc_mv_poly(polynomial)
    }

    /// Tracks a materialized polynomial.
    ///
    /// moves the polynomial to heap, assigns a TracckerID to it in map and
    /// returns the TrackerID
    pub fn track_mat_uv_poly(&mut self, polynomial: LDE<B::F>) -> TrackerID {
        let polynomial = Arc::new(polynomial);
        self.track_mat_arc_uv_poly(polynomial)
    }
    /// Tracks materialized polynomial by reference.
    ///
    /// Assumes the input polynomial is already on the heap and assigns a
    /// TrackerID to it in the map
    fn track_mat_arc_mv_poly(&mut self, polynomial: Arc<MLE<B::F>>) -> TrackerID {
        // Create the new TrackerID
        let poly_id = self.gen_id();

        // Add the polynomial to the materialized map
        self.state
            .mv_pcs_substate
            .materialized_polys
            .insert(poly_id, polynomial.clone());
        self.state.num_vars.insert(poly_id, polynomial.num_vars());
        // Return the new TrackerID
        poly_id
    }

    fn track_mat_arc_uv_poly(&mut self, polynomial: Arc<LDE<B::F>>) -> TrackerID {
        // Create the new TrackerID
        let poly_id = self.gen_id();

        // Add the polynomial to the materialized map
        self.state
            .uv_pcs_substate
            .materialized_polys
            .insert(poly_id, polynomial.clone());

        // Return the new TrackerID
        poly_id
    }

    /// Tracks a materialized polynomial and sends a commitment to the verifier.
    pub fn track_and_commit_mat_mv_p(&mut self, polynomial: &MLE<B::F>) -> SnarkResult<TrackerID> {
        let polynomial = Arc::new(polynomial.clone());
        // commit to the polynomial
        let commitment = B::MvPCS::commit(self.pk.mv_pcs_param.as_ref(), &polynomial)?;
        Self::track_mat_mv_p_and_commitment(self, &polynomial, commitment)
    }

    pub fn track_mat_mv_p_and_commitment(
        &mut self,
        polynomial: &MLE<B::F>,
        commitment: <B::MvPCS as PCS<B::F>>::Commitment,
    ) -> SnarkResult<TrackerID> {
        let polynomial = Arc::new(polynomial.clone());
        // commit to the polynomial

        // track the polynomial and get its id
        let poly_id = self.track_mat_arc_mv_poly(polynomial);

        // add the commitment to the commitment map with the same poly_id
        self.state
            .mv_pcs_substate
            .materialized_comms
            .insert(poly_id, commitment.clone());

        // Add the commitment to the transcript, since it will be sent to the verifier
        self.state
            .transcript
            .append_serializable_element(b"comm", &commitment)?;
        // Return the new TrackerID
        Ok(poly_id)
    }

    pub fn track_and_commit_mat_uv_poly(
        &mut self,
        polynomial: LDE<B::F>,
    ) -> SnarkResult<TrackerID> {
        let polynomial = Arc::new(polynomial);
        // commit to the polynomial
        let commitment = B::UvPCS::commit(self.pk.uv_pcs_param.as_ref(), &polynomial)?;
        Self::track_mat_uv_p_and_commitment(self, &polynomial, commitment)
    }

    fn track_mat_uv_p_and_commitment(
        &mut self,
        polynomial: &LDE<B::F>,
        commitment: <B::UvPCS as PCS<B::F>>::Commitment,
    ) -> SnarkResult<TrackerID> {
        let polynomial = Arc::new(polynomial.clone());

        // track the polynomial and get its id
        let poly_id = self.track_mat_arc_uv_poly(polynomial);

        // add the commitment to the commitment map with the same poly_id
        self.state
            .uv_pcs_substate
            .materialized_comms
            .insert(poly_id, commitment.clone());

        // Add the commitment to the transcript, since it will be sent to the verifier
        self.state
            .transcript
            .append_serializable_element(b"comm", &commitment)?;
        // Return the new TrackerID
        Ok(poly_id)
    }

    /// Tracks a virtual polynomial
    ///
    /// generates a new TrackerID and adds the virtual polynomial to the map
    fn track_virt_poly(&mut self, p: VirtualPoly<B::F>) -> TrackerID {
        let poly_id = self.gen_id();

        let nv = p
            .iter()
            .flat_map(|(_, prod_ids)| prod_ids.iter().map(|id| self.state.num_vars[id]))
            .max()
            .unwrap_or_default();
        self.state.num_vars.insert(poly_id, nv);
        self.state.virtual_polys.insert(poly_id, p);
        // No need to commit to virtual polynomials
        poly_id
    }

    /// Get a reference to a materialized multivariate polynomial on the heap,
    /// from the map, by its TrackerID
    pub fn mat_mv_poly(&self, id: TrackerID) -> Option<&Arc<MLE<B::F>>> {
        self.state.mv_pcs_substate.materialized_polys.get(&id)
    }

    /// Get a reference to a materialized univariate polynomial on the heap,
    /// from the map, by its TrackerID
    pub fn mat_uv_poly(&self, id: TrackerID) -> Option<&Arc<LDE<B::F>>> {
        self.state.uv_pcs_substate.materialized_polys.get(&id)
    }

    /// Get a virtual polynomial, from the map, by its TrackerID
    pub fn virt_poly(&self, id: TrackerID) -> Option<&VirtualPoly<B::F>> {
        self.state.virtual_polys.get(&id)
    }
    fn extract_mv_openable_ids(&self, id: TrackerID) -> BTreeSet<TrackerID> {
        if self
            .state
            .mv_pcs_substate
            .materialized_comms
            .contains_key(&id)
        {
            return BTreeSet::from([id]);
        }
        let poly = self.virt_poly(id).unwrap();
        // 1)  Initialise the DFS stack with every TrackerID mentioned up-front
        let mut stack: Vec<TrackerID> = poly
            .iter()
            .flat_map(|(_, ids)| ids.iter().copied())
            .collect();

        let mut openable = BTreeSet::new();
        let mut visited = HashSet::new();

        // 2)  Standard iterative DFS
        while let Some(id) = stack.pop() {
            if !visited.insert(id) {
                continue; // already explored
            }

            // a) leaf with concrete commitment?
            if self
                .state
                .mv_pcs_substate
                .materialized_comms
                .contains_key(&id)
            {
                openable.insert(id);
                continue; // do *not* push children
            }

            // b) otherwise follow the virtual-poly reference if it exists
            if let Some(vpoly) = self.state.virtual_polys.get(&id) {
                for (_, child_ids) in vpoly.iter() {
                    stack.extend(child_ids.iter().copied());
                }
            }
            // c) dangling reference ⇒ silently ignore
        }

        openable
    }

    fn extract_uv_openable_ids(&self, id: TrackerID) -> BTreeSet<TrackerID> {
        if self
            .state
            .uv_pcs_substate
            .materialized_comms
            .contains_key(&id)
        {
            return BTreeSet::from([id]);
        }
        let poly = self.virt_poly(id).unwrap();
        // 1)  Initialise the DFS stack with every TrackerID mentioned up-front
        let mut stack: Vec<TrackerID> = poly
            .iter()
            .flat_map(|(_, ids)| ids.iter().copied())
            .collect();

        let mut openable = BTreeSet::new();
        let mut visited = HashSet::new();

        // 2)  Standard iterative DFS
        while let Some(id) = stack.pop() {
            if !visited.insert(id) {
                continue; // already explored
            }

            // a) leaf with concrete commitment?
            if self
                .state
                .uv_pcs_substate
                .materialized_comms
                .contains_key(&id)
            {
                openable.insert(id);
                continue; // do *not* push children
            }

            // b) otherwise follow the virtual-poly reference if it exists
            if let Some(vpoly) = self.state.virtual_polys.get(&id) {
                for (_, child_ids) in vpoly.iter() {
                    stack.extend(child_ids.iter().copied());
                }
            }
            // c) dangling reference ⇒ silently ignore
        }

        openable
    }

    /// Get the number of variables of a polynomial, by its TrackerID
    pub fn poly_nv(&self, id: TrackerID) -> usize {
        self.state.num_vars.get(&id).copied().unwrap()
    }

    /// Return the max multiplicative degree (max number of MLEs in any product)
    /// of the virtual-poly tree rooted at `id`, matching HPVirtualPolynomial::max_degree.
    pub fn virt_poly_degree(&self, id: TrackerID) -> usize {
        let mut memo = HashMap::new();
        let mut visiting = HashSet::new();
        self.virt_poly_degree_inner(id, &mut memo, &mut visiting)
    }

    fn virt_poly_degree_inner(
        &self,
        id: TrackerID,
        memo: &mut HashMap<TrackerID, usize>,
        visiting: &mut HashSet<TrackerID>,
    ) -> usize {
        if let Some(&cached) = memo.get(&id) {
            return cached;
        }
        if self.mat_mv_poly(id).is_some() {
            memo.insert(id, 1);
            return 1;
        }
        let Some(vpoly) = self.state.virtual_polys.get(&id) else {
            return 0;
        };
        if !visiting.insert(id) {
            return 0;
        }
        let mut max_degree = 0;
        for (_, prod_ids) in vpoly.iter() {
            let mut term_degree = 0;
            for child_id in prod_ids {
                term_degree += self.virt_poly_degree_inner(*child_id, memo, visiting);
            }
            if term_degree > max_degree {
                max_degree = term_degree;
            }
        }
        visiting.remove(&id);
        memo.insert(id, max_degree);
        max_degree
    }

    /// Adds/Subtracts two polynomials together
    /// The two polynomials are identified by their TrackerIDs, Each one can be
    /// either materialized or virtual
    /// The output is a tracker to a new virtual polynomial
    pub fn add_sub_polys(&mut self, p1: TrackerID, p2: TrackerID, do_sub: bool) -> TrackerID {
        let sign_coeff: B::F = if do_sub { -B::F::one() } else { B::F::one() };

        let p1_mat = self.mat_mv_poly(p1);
        let p1_virt = self.virt_poly(p1);
        let p2_mat = self.mat_mv_poly(p2);
        let p2_virt = self.virt_poly(p2);

        let mut new = VirtualPoly::new(); // Invariant: contains only material TrackerIDs
        match (p1_mat, p1_virt, p2_mat, p2_virt) {
            (Some(_), None, Some(_), None) => {
                new.push((B::F::one(), vec![p1]));
                new.push((sign_coeff, vec![p2]));
            }

            // p1: materialized, p2: virtual
            (Some(_), None, None, Some(p2)) => {
                new.push((B::F::one(), vec![p1]));
                new.extend(
                    p2.iter()
                        .map(|(coeff, prod)| (*coeff * sign_coeff, prod.clone())),
                );
            }
            // p1: virtual, p2: materialized
            (None, Some(p1), Some(_), None) => {
                new.push((sign_coeff, vec![p2]));
                new.extend_from_slice(p1);
            }
            (None, Some(p1), None, Some(p2)) => {
                new.extend_from_slice(p1);
                new.extend(
                    p2.iter()
                        .map(|(coeff, prod)| (*coeff * sign_coeff, prod.clone())),
                );
            }
            (None, None, _, _) => panic!("Unknown p1 TrackerID {p1:?}"),
            (_, _, None, None) => panic!("Unknown p2 TrackerID {p2:?}"),
            (_, _, _, _) => unreachable!(),
        }
        self.track_virt_poly(new)
    }

    /// Adds two polynomials together
    /// The two polynomials are identified by their TrackerIDs, Each one can be
    /// either materialized or virtual
    /// The output is a tracker to a new virtual polynomial
    pub fn add_polys(&mut self, p1_id: TrackerID, p2_id: TrackerID) -> TrackerID {
        self.add_sub_polys(p1_id, p2_id, false)
    }

    /// Subtracts p2 from p1
    /// The two polynomials are identified by their TrackerIDs, Each one can be
    /// either materialized or virtual
    /// The output is a tracker to a new virtual polynomial
    pub fn sub_polys(&mut self, p1_id: TrackerID, p2_id: TrackerID) -> TrackerID {
        self.add_sub_polys(p1_id, p2_id, true)
    }

    /// Multiplies two polynomials together
    /// The two polynomials are identified by their TrackerIDs, Each one can be
    /// either materialized or virtual
    /// The output is a tracker to a new virtual polynomial
    pub fn mul_polys(&mut self, p1: TrackerID, p2: TrackerID) -> TrackerID {
        let p1_mat = self.mat_mv_poly(p1);
        let p1_virt = self.virt_poly(p1);
        let p2_mat = self.mat_mv_poly(p2);
        let p2_virt = self.virt_poly(p2);

        let mut new = VirtualPoly::new(); // Invariant: contains only material TrackerIDs
        match (p1_mat, p1_virt, p2_mat, p2_virt) {
            // Bad Case: p1 not found
            (None, None, ..) => panic!("Unknown p1 TrackerID {p1:?}"),
            // Bad Case: p2 not found
            (_, _, None, None) => panic!("Unknown p1 TrackerID {p2:?}"),
            // Case 1: both p1 and p2 are materialized
            (Some(_), None, Some(_), None) => new.push((B::F::one(), vec![p1, p2])),
            // Case 2: p1 is materialized and p2 is virtual
            (Some(_), None, None, Some(p)) => {
                p.iter().cloned().for_each(|(coeff, mut prod)| {
                    prod.push(p1);
                    new.push((coeff, prod));
                });
            }
            (None, Some(p), Some(_), None) => {
                p.iter().cloned().for_each(|(coeff, mut prod)| {
                    prod.push(p2);
                    new.push((coeff, prod));
                });
            }
            // Case 3: both p1 and p2 are virtual
            (None, Some(p1), None, Some(p2)) => {
                for (coeff1, prod1) in p1 {
                    for (coeff2, prod2) in p2 {
                        let mut prod1 = prod1.clone();
                        prod1.extend_from_slice(prod2);
                        new.push((*coeff1 * *coeff2, prod1));
                    }
                }
            }
            (_, _, _, _) => unreachable!(),
        };
        self.track_virt_poly(new)
    }

    /// Adds a scalar to a polynomial, returns a new virtual polynomial
    // TODO: Can we do it more efficiently?
    pub fn add_scalar(&mut self, poly_id: TrackerID, c: B::F) -> TrackerID {
        let nv = self.poly_nv(poly_id);
        let scalar_mle = MLE::from_evaluations_vec(nv, vec![c; 2_usize.pow(nv as u32)]);
        let scalar_id = self.track_mat_mv_poly(scalar_mle);
        self.add_polys(poly_id, scalar_id)
    }

    /// Multiplies a polynomial by a scalar, returns a new virtual polynomial
    pub fn mul_scalar(&mut self, poly_id: TrackerID, c: B::F) -> TrackerID {
        let mut new = VirtualPoly::new();
        match self.mat_mv_poly(poly_id) {
            Some(_) => new.push((c, vec![poly_id])),
            None => {
                let p = self.virt_poly(poly_id).unwrap();
                p.iter().for_each(|(coeff, prod)| {
                    new.push((*coeff * c, prod.clone()));
                });
            }
        }
        self.track_virt_poly(new)
    }

    fn materialize_poly(&mut self, id: TrackerID) -> Arc<MLE<B::F>> {
        match self.mat_mv_poly(id) {
            Some(mat_poly) => return mat_poly.clone(), // already materialized
            None => {
                let virt_poly = self.state.virtual_polys[&id].clone();
                // Invariant: contains only material PolyIDs
                assert!(
                    virt_poly
                        .iter()
                        .all(|(_, ids)| ids.iter().all(|id| self.mat_mv_poly(*id).is_some()))
                );
                // Ensure all the product polynomials have the same number of variables
                // assert_eq!(
                //     virt_poly
                //         .iter()
                //         .flat_map(|(_, ids)| ids.iter().map(|id| self.poly_nv(*id)))
                //         .collect::<HashSet<_>>()
                //         .len(),
                //     1
                // );
                let nv = self.poly_nv(id);

                let evals = virt_poly.iter().fold(
                    vec![B::F::ZERO; 1 << nv],
                    |mut acc, (coeff, products)| {
                        let t = products.iter().fold(vec![*coeff; 1 << nv], |mut acc, id| {
                            cfg_iter_mut!(acc)
                                .zip(self.mat_mv_poly(*id).unwrap().evaluations())
                                .for_each(|(a, b)| *a *= b);
                            acc
                        });
                        cfg_iter_mut!(acc).zip(t).for_each(|(a, b)| *a += b);
                        acc
                    },
                );
                Arc::new(MLE::from_evaluations_vec(nv, evals))
            }
        }
    }

    pub fn evaluate_uv(&self, id: TrackerID, pt: &B::F) -> Option<B::F> {
        let mat_poly = self.state.uv_pcs_substate.materialized_polys.get(&id);
        // TODO: Change this to_vec
        mat_poly.map(|poly| poly.evaluate(pt))
    }

    /// Evaluates a polynomial at a point
    pub fn evaluate_mv(&self, id: TrackerID, pt: &[B::F]) -> Option<B::F> {
        match self.state.mv_pcs_substate.materialized_polys.get(&id) {
            Some(poly) => {
                let nv = poly.mat_mle().num_vars;
                if nv == 0 {
                    // Avoid build_eq_x_r([]) for constant polynomials.
                    return poly.mat_mle().evaluations.get(0).copied();
                }
                let eq_eval = build_eq_x_r(&pt[..nv]).unwrap();
                Some(evaluate_with_eq(poly, &eq_eval))
            }
            None => {
                let p = self.virt_poly(id).unwrap();
                // calculate the evaluation of each product list
                let result = p
                    .iter()
                    .map(|(coeff, prod)| {
                        *coeff
                            * prod
                                .iter()
                                .map(|poly| self.evaluate_mv(*poly, pt).unwrap())
                                .product::<B::F>()
                    })
                    .sum::<B::F>();
                Some(result)
            }
        }
    }

    /// Evaluates a polynomial at a point given the evaluations of the eq polynomial at that point.
    /// This assumes that `eq_evals` contains the evaluations of the eq polynomial for each number
    /// of variables of the *actual* underlying `DenseMultilinearExtension` of the materialized polynomials.
    pub fn evaluate_mv_with_eq_evals(
        &self,
        id: TrackerID,
        eq_evals: &BTreeMap<usize, MLE<B::F>>,
    ) -> Option<B::F> {
        match self.state.mv_pcs_substate.materialized_polys.get(&id) {
            Some(poly) => {
                let nv = poly.mat_mle().num_vars;
                Some(evaluate_with_eq(poly, &eq_evals[&nv]))
            }
            None => {
                let p = self.virt_poly(id).unwrap();
                let result = p
                    .iter()
                    .map(|(coeff, prod)| {
                        *coeff
                            * prod
                                .iter()
                                .map(|poly| {
                                    self.evaluate_mv_with_eq_evals(*poly, eq_evals).unwrap()
                                })
                                .product::<B::F>()
                    })
                    .sum::<B::F>();
                Some(result)
            }
        }
    }

    /// Returns the evaluations of a polynomial on the boolean hypercube
    pub fn evaluations(&mut self, id: TrackerID) -> Vec<B::F> {
        // Ensure the polynomial is materialized before getting evaluations
        let mat_poly = self.materialize_poly(id);

        mat_poly.evaluations()
    }

    /// Generate the challenge from the current transcript
    /// and append it to the transcript.
    pub fn get_and_append_challenge(&mut self, label: &'static [u8]) -> SnarkResult<B::F> {
        self.state
            .transcript
            .get_and_append_challenge(label)
            .map_err(SnarkError::from)
    }

    /// Adds a sumcheck claim to the list of the sumcheck claims of the prover
    /// a sumcheck claim is of the form (poly_id, claimed_sum) which means that
    /// the prover claims that the sum of the evaluations of the polynomial with
    /// poly_id is claimed_sum
    // TODO: Remove the claimed_sum
    pub fn add_mv_sumcheck_claim(
        &mut self,
        poly_id: TrackerID,
        claimed_sum: B::F,
    ) -> SnarkResult<()> {
        #[cfg(feature = "honest-prover")]
        {
            let evals = self.evaluations(poly_id);
            let real_sum = cfg_iter!(evals).sum::<B::F>();
            if real_sum != claimed_sum {
                tracing::error!(
                    "honest prover sumcheck mismatch: real_sum={:?} claimed_sum={:?}",
                    real_sum,
                    claimed_sum
                );
                return Err(ProverError(HonestProverError(FalseClaim)));
            }
        }
        self.state
            .mv_pcs_substate
            .sum_check_claims
            .push(TrackerSumcheckClaim::new(poly_id, claimed_sum));
        Ok(())
    }

    /// Adds a zerocheck claim to the list of the zerocheck claims of the prover
    /// a zerocheck claim is of the form (poly_id) which means that the prover
    /// claims that the polynomial with poly_id evaluates to zero all over the
    /// boolean hypercube
    pub fn add_mv_zerocheck_claim(&mut self, poly_id: TrackerID) -> SnarkResult<()> {
        if let Some(poly) = self.virt_poly(poly_id) {
            trace!(?poly_id, ?poly, "add_mv_zerocheck_claim virtual");
        } else {
            trace!(?poly_id, "add_mv_zerocheck_claim materialized");
        }
        #[cfg(feature = "honest-prover")]
        {
            let evals = self.evaluations(poly_id);
            if cfg_iter!(evals).any(|eval| *eval != B::F::zero()) {
                tracing::error!("The emitted Zerocheck claim is false");
                return Err(ProverError(HonestProverError(FalseClaim)));
            }
        }
        self.state
            .mv_pcs_substate
            .zero_check_claims
            .push(TrackerZerocheckClaim::new(poly_id));
        Ok(())
    }

    /// Adds a nozerocheck claim to the list of the nozerocheck claims of the prover
    /// a nozerocheck claim is of the form (poly_id) which means that the prover
    /// claims that the polynomial with poly_id evaluates to zero all over the
    /// boolean hypercube
    pub fn add_mv_nozerocheck_claim(&mut self, poly_id: TrackerID) -> SnarkResult<()> {
        if let Some(poly) = self.virt_poly(poly_id) {
            trace!(?poly_id, ?poly, "add_mv_nozerocheck_claim virtual");
        } else {
            trace!(?poly_id, "add_mv_nozerocheck_claim materialized");
        }
        #[cfg(feature = "honest-prover")]
        {
            let evals = self.evaluations(poly_id);
            if cfg_iter!(evals).any(|eval| *eval == B::F::zero()) {
                tracing::error!("error");
                return Err(ProverError(HonestProverError(FalseClaim)));
            }
        }
        self.state
            .mv_pcs_substate
            .no_zero_check_claims
            .push(TrackerNoZerocheckClaim::new(poly_id));
        Ok(())
    }

    /// Add a multivariate lookup claim to the proof
    #[instrument(level = "debug", skip(self))]
    pub fn add_mv_lookup_claim(
        &mut self,
        super_id: TrackerID,
        sub_id: TrackerID,
    ) -> SnarkResult<()> {
        #[cfg(feature = "honest-prover")]
        {
            let super_evals = self.evaluations(super_id);
            let sub_evals = self.evaluations(sub_id);
            let super_eval_set: HashSet<B::F> = super_evals.into_iter().collect();
            if cfg_iter!(sub_evals).any(|eval| !super_eval_set.contains(eval)) {
                tracing::error!("error");
                return Err(ProverError(HonestProverError(FalseClaim)));
            }
        }
        self.state
            .mv_pcs_substate
            .lookup_claims
            .push(TrackerLookupClaim::new(super_id, sub_id));
        Ok(())
    }

    pub(crate) fn take_lookup_claims(&mut self) -> Vec<TrackerLookupClaim> {
        take(&mut self.state.mv_pcs_substate.lookup_claims)
    }

    /// Adds an evaluation claim to the list of the zerocheck claims of the
    /// prover a zerocheck claim is of the form (poly_id) which means that
    /// the prover claims that the polynomial with poly_id evaluates to zero
    /// all over the boolean hypercube
    pub fn add_uv_eval_claim(&mut self, poly_id: TrackerID, point: B::F) -> SnarkResult<()> {
        self.state
            .uv_pcs_substate
            .eval_claims
            .push(TrackerEvalClaim::new(poly_id, point));
        Ok(())
    }

    pub fn insert_miscellaneous_field(&mut self, key: String, field: B::F) {
        self.state.miscellaneous_field_elements.insert(key, field);
    }

    pub fn miscellaneous_field_element(&self, label: &str) -> SnarkResult<B::F> {
        self.state
            .miscellaneous_field_elements
            .get(label)
            .cloned()
            .ok_or(SnarkError::DummyError)
    }

    pub fn add_mv_eval_claim(&mut self, poly_id: TrackerID, point: &[B::F]) -> SnarkResult<()> {
        self.state
            .mv_pcs_substate
            .eval_claims
            .push(TrackerEvalClaim::new(poly_id, point.to_vec()));
        Ok(())
    }

    // TODO: Is this only used to be compatible with the hyperplonk code?
    #[instrument(level = "debug", skip_all)]
    pub(crate) fn to_hp_virtual_poly(&self, id: TrackerID) -> HPVirtualPolynomial<B::F> {
        let mat_poly = self.state.mv_pcs_substate.materialized_polys.get(&id);
        if let Some(poly) = mat_poly {
            return HPVirtualPolynomial::new_from_mle(poly, B::F::one());
        }

        let poly = self.state.virtual_polys.get(&id);
        if poly.is_none() {
            panic!("Unknown poly id: {:?}", id);
        }
        let poly = poly.unwrap(); // Invariant: contains only material PolyIDs
        if poly.is_empty() {
            return HPVirtualPolynomial::new(1);
        }
        let first_id = poly[0].1[0];
        let nv: usize = self.mat_mv_poly(first_id).unwrap().num_vars();

        // Optimize away linear combinations of committed polynomials by
        // materializing them into fresh MLEs (no new commitments). Identical
        // linear combos are deduplicated so (a+b)*d + (a+b)*e becomes c*d + c*e.
        let (poly_terms, optimized_terms) = self.optimize_linear_terms(poly, nv);

        let mut arith_virt_poly: HPVirtualPolynomial<B::F> = HPVirtualPolynomial::new(nv);
        for (prod_coef, prod) in poly_terms.iter() {
            let prod_mle_list = prod
                .iter()
                .map(|poly_id| self.mat_mv_poly(*poly_id).unwrap().clone())
                .collect::<Vec<Arc<MLE<B::F>>>>();
            arith_virt_poly
                .add_mle_list(prod_mle_list, *prod_coef)
                .unwrap();
        }

        for (coef, mles) in optimized_terms {
            arith_virt_poly.add_mle_list(mles, coef).unwrap();
        }

        arith_virt_poly
    }

    /// Pulls out linear terms (single committed MLEs and constants) from a virtual
    /// polynomial and materializes them into fresh MLEs. Identical linear combos
    /// are deduplicated so (a+b)*d + (a+b)*e becomes c*d + c*e.
    fn optimize_linear_terms(
        &self,
        poly: &VirtualPoly<B::F>,
        nv: usize,
    ) -> (
        Vec<(B::F, Vec<TrackerID>)>,
        Vec<(B::F, Vec<Arc<MLE<B::F>>>)>,
    ) {
        let mut constant = B::F::zero();
        let mut term_used = vec![false; poly.len()];
        let mut other_terms: Vec<(B::F, Vec<TrackerID>)> = Vec::new();
        let mut optimized_terms: Vec<(B::F, Vec<Arc<MLE<B::F>>>)> = Vec::new();

        // context -> [(term_idx, factor_id, coeff)]
        // We pick a single, deterministic split per term to avoid double counting.
        let mut context_map: BTreeMap<Vec<TrackerID>, Vec<(usize, TrackerID, B::F)>> =
            BTreeMap::new();

        for (idx, (coeff, prod)) in poly.iter().enumerate() {
            if prod.is_empty() {
                constant += *coeff;
                term_used[idx] = true;
                continue;
            }

            let mut sorted_prod = prod.clone();
            sorted_prod.sort();

            // Deterministically choose the linear factor as the smallest id.
            let factor = sorted_prod[0];
            let context = sorted_prod[1..].to_vec();

            context_map
                .entry(context)
                .or_default()
                .push((idx, factor, *coeff));
        }

        // Cache linear combos to deduplicate across different contexts.
        let mut linear_cache: Vec<(Vec<(TrackerID, B::F)>, Arc<MLE<B::F>>)> = Vec::new();

        for (context, entries) in context_map.into_iter() {
            let active_entries: Vec<(usize, TrackerID, B::F)> = entries
                .into_iter()
                .filter(|(idx, _, _)| !term_used[*idx])
                .collect();
            if active_entries.len() < 2 {
                continue;
            }

            // Build linear combo signature for this context.
            let mut signature_map: BTreeMap<TrackerID, B::F> = BTreeMap::new();
            for (_, factor, coeff) in &active_entries {
                *signature_map.entry(*factor).or_insert_with(B::F::zero) += *coeff;
            }
            signature_map.retain(|_, c| !c.is_zero());
            // Skip single-MLE linear terms (a) or degenerate combos.
            if signature_map.len() <= 1 {
                continue;
            }

            // Ensure all factors have matching nv.
            if signature_map.iter().any(|(id, _)| {
                self.mat_mv_poly(*id)
                    .map(|mle| mle.num_vars() != nv)
                    .unwrap_or(true)
            }) {
                continue;
            }

            let signature: Vec<(TrackerID, B::F)> = signature_map.into_iter().collect();

            // Reuse or build the linear combo MLE.
            let linear_mle = if let Some((_, mle)) =
                linear_cache.iter().find(|(sig, _)| *sig == signature)
            {
                mle.clone()
            } else {
                let mut evals = vec![B::F::zero(); 1 << nv];
                for (id, coeff) in &signature {
                    let mle = self.mat_mv_poly(*id).unwrap();
                    cfg_iter_mut!(evals)
                        .zip(mle.evaluations())
                        .for_each(|(acc, v)| *acc += *coeff * v);
                }
                let mle = Arc::new(MLE::from_evaluations_vec(nv, evals));
                linear_cache.push((signature.clone(), mle.clone()));
                mle
            };

            // Mark terms as used.
            for (idx, _, _) in &active_entries {
                term_used[*idx] = true;
            }

            // Build product: linear_mle * context_mles
            let mut mles: Vec<Arc<MLE<B::F>>> = Vec::with_capacity(1 + context.len());
            mles.push(linear_mle);
            for id in &context {
                mles.push(self.mat_mv_poly(*id).unwrap().clone());
            }
            optimized_terms.push((B::F::one(), mles));
        }

        // Add remaining unused terms as-is.
        for (idx, (coeff, prod)) in poly.iter().enumerate() {
            if !term_used[idx] {
                other_terms.push((*coeff, prod.clone()));
            }
        }

        // If a constant remains, materialize it as a standalone MLE.
        if !constant.is_zero() {
            let evals = vec![constant; 1 << nv];
            optimized_terms.push((
                B::F::one(),
                vec![Arc::new(MLE::from_evaluations_vec(nv, evals))],
            ));
        }

        (other_terms, optimized_terms)
    }

    /// Iterates through the materialized polynomials and increases the number
    /// of variables to the max number of variables in the tracker
    /// Used as a preprocessing step before batching polynomials,
    // TODO: This can be potentially reduced
    #[instrument(level = "debug", skip(self))]
    fn equalize_mat_poly_nv(&mut self) -> usize {
        // calculate the max nv
        let max_nv = self.state.num_vars.values().max().copied().unwrap_or(0);

        for poly in self.state.mv_pcs_substate.materialized_polys.values_mut() {
            let old_nv = poly.num_vars();
            if old_nv != max_nv {
                let inner_poly = Arc::get_mut(poly).unwrap();
                let inner = std::mem::take(inner_poly.mat_mle_mut());
                *poly = Arc::new(MLE::new(inner, Some(max_nv)));
            }
        }

        for claim in &mut self.state.mv_pcs_substate.sum_check_claims {
            let nv = self.state.num_vars[&claim.id()];
            claim.set_claim(claim.claim() * B::F::from(1 << (max_nv - nv)))
        }

        for claim in self.state.mv_pcs_substate.eval_claims.iter_mut() {
            let mut point = claim.point().clone();
            point.resize(max_nv, B::F::zero());
            claim.set_point(point);
        }
        max_nv
    }

    /// converts all the zerocheck claims into a single zero claim
    /// technique: If p1=0, ..., pn=0, then c1*p1 + ... + cn*pn = 0 where ci-s
    /// are random. At the end of this function, there should only be one
    /// zerocheck claim in the prover state.
    #[instrument(level = "debug", skip(self))]
    fn batch_z_check_claims(&mut self) -> SnarkResult<()> {
        debug!(
            "Zerocheck claims with degrees: {}",
            self.state
                .mv_pcs_substate
                .zero_check_claims
                .iter()
                .map(|claim| self.virt_poly_degree(claim.id()))
                .collect::<Vec<usize>>()
                .iter()
                .map(|d| d.to_string())
                .collect::<Vec<String>>()
                .join(", ")
        );
        let num_claims = self.state.mv_pcs_substate.zero_check_claims.len();

        if num_claims == 0 {
            debug!("No zerocheck claims to batch",);
            return Ok(());
        }

        // build the running aggregate polynomial
        let mut agg = self.track_virt_poly(VirtualPoly::new());
        // Perform the random linear combination and aggregate them
        agg = take(&mut self.state.mv_pcs_substate.zero_check_claims)
            .into_iter()
            .fold(agg, |acc, claim| {
                let ch = self
                    .get_and_append_challenge(b"zerocheck challenge")
                    .unwrap();
                let cp = self.mul_scalar(claim.id(), ch);
                self.add_polys(acc, cp)
            });

        // Push the new aggregated claim to the prover state as the inly zerocheck claim
        self.add_mv_zerocheck_claim(agg)?;
        debug!(
            "{} zerocheck claims were batched into 1 zerocheck claim with degree {}",
            num_claims,
            self.virt_poly_degree(agg)
        );
        Ok(())
    }

    // Aggregate the sumcheck claims, instead of proving p_1 = s_1, p_2 = s_2, ...
    // p_n = s_n, we prove c_1 * p_1 + c_2 * p_2 + ... + c_n * p_n = c_1 *
    // s_1 + c_2 * s_2 + ... + c_n * s_n where c_i-s are random challenges
    #[instrument(level = "debug", skip(self))]
    fn batch_s_check_claims(&mut self) -> SnarkResult<BTreeMap<TrackerID, B::F>> {
        let num_claims = self.state.mv_pcs_substate.sum_check_claims.len();

        if num_claims == 0 {
            debug!("No sumcheck claims to batch",);
            return Ok(BTreeMap::new());
        }

        let mut agg = self.track_virt_poly(VirtualPoly::new());
        let mut sc_sum = B::F::zero();

        // Record the individual sumcheck claims to send to the verifier
        //TODO: This is only recorded for a specific protocol that uses this library and needs these, i.e. multiplicity-check. This should be removed from the library and added to the user-defined optional proof elements.
        let individual_sumcheck_claims: BTreeMap<TrackerID, B::F> = self
            .state
            .mv_pcs_substate
            .sum_check_claims
            .iter()
            .map(|claim| (claim.id(), claim.claim()))
            .collect();

        // Perform the random linear combination and aggregate them
        agg = take(&mut self.state.mv_pcs_substate.sum_check_claims)
            .into_iter()
            .fold(agg, |acc, claim| {
                let ch = self
                    .get_and_append_challenge(b"sumcheck challenge")
                    .unwrap();
                let cp = self.mul_scalar(claim.id(), ch);
                sc_sum += claim.claim() * ch;
                self.add_polys(acc, cp)
            });
        // Now the sumcheck claims are empty
        // Add the new aggregated sumcheck claim to the list of claims
        self.add_mv_sumcheck_claim(agg, sc_sum)?;
        debug!(
            "{} sumcheck claims were batched into 1 sumcheck claim",
            num_claims
        );
        Ok(individual_sumcheck_claims)
    }

    /// Convert the zerocheck claim to a sumcheck claim
    /// Note that at this point, there is only one batched
    /// zero-check
    /// Technique: Run a sumcheck over f'(X) = f(X) * eq(X, r) for a random
    /// challenge r
    #[instrument(level = "debug", skip(self))]
    fn z_check_claim_to_s_check_claim(&mut self, max_nv: usize) -> SnarkResult<()> {
        if self.state.mv_pcs_substate.zero_check_claims.is_empty() {
            debug!("No zerocheck claims to convert to sumcheck claims",);
            return Ok(());
        }
        // Check at this point there should be only one batched zero check claim
        debug_assert_eq!(self.state.mv_pcs_substate.zero_check_claims.len(), 1);
        // sample the random challenge r
        let r = self
            .state
            .transcript
            .get_and_append_challenge_vectors(b"0check r", max_nv)
            .unwrap();
        // Get the zero check claim polynomial id
        let z_check_aggr_id = self
            .state
            .mv_pcs_substate
            .zero_check_claims
            .last()
            .unwrap()
            .id();

        // build the eq(x, r) polynomial
        let eq_x_r_id = self.track_mat_arc_mv_poly(build_eq_x_r(r.as_ref()).unwrap());

        // create the relevant sumcheck claim, i.e. reduce the zerocheck claim to a
        // sumcheck claim
        let new_sc_claim_poly = self.mul_polys(z_check_aggr_id, eq_x_r_id);

        // Add this new sumcheck claim to other sumcheck claims
        self.add_mv_sumcheck_claim(new_sc_claim_poly, B::F::zero())?;
        // Clear the zerocheck claim: it has been converted into a sumcheck claim.
        self.state.mv_pcs_substate.zero_check_claims.clear();
        debug!(
            "The only zerocheck claim was converted to a sumcheck claim with degree {}",
            self.virt_poly_degree(new_sc_claim_poly)
        );
        Ok(())
    }

    #[instrument(level = "debug", skip(self))]
    fn perform_single_sumcheck(&mut self) -> SnarkResult<(SumcheckProof<B::F>, VPAuxInfo<B::F>)> {
        assert!(self.state.mv_pcs_substate.sum_check_claims.len() == 1);

        // Get the sumcheck claim polynomial id
        let sumcheck_aggr_id = self
            .state
            .mv_pcs_substate
            .sum_check_claims
            .last()
            .unwrap()
            .id();
        // Generate a sumcheck proof

        let sc_avp = self.to_hp_virtual_poly(sumcheck_aggr_id);
        debug!(
            "The final virtual polynomial for sumcheck has {} terms, {} degree, and {} number of variables",
            sc_avp.products.len(),
            sc_avp.aux_info.max_degree,
            sc_avp.aux_info.num_variables
        );
        let sc_aux_info = sc_avp.aux_info.clone();
        let sc_proof = SumCheck::prove(&sc_avp, &mut self.state.transcript)?;
        let _ = self.add_mv_eval_claim(sumcheck_aggr_id, &sc_proof.point);
        Ok((sc_proof, sc_aux_info))
    }

    pub fn get_or_build_contig_one_poly(
        &mut self,
        nv: usize,
        s: usize,
    ) -> SnarkResult<TrackedPoly<B>> {
        let label = format!("contig_one_nv{}_s{}", nv, s);
        if let Some(poly) = self.state.indexed_tracked_polys.get(&label) {
            return Ok(poly.clone());
        }

        let total = 1usize << nv;
        if s > total {
            return Err(SnarkError::SetupError(NoRangePoly(format!(
                "contig_one_poly has s > 2^nv: s={}, nv={}",
                s, nv
            ))));
        }

        let mut evals = vec![B::F::zero(); total];
        evals[..s].fill(B::F::one());
        let mle = MLE::from_evaluations_vec(nv, evals);
        let poly_id = self.track_mat_mv_poly(mle);

        let tracker_rc = if let Some(poly) = self.state.indexed_tracked_polys.values().next() {
            poly.tracker()
        } else if let Some(self_rc) = &self.self_rc {
            let tracker_rc: Rc<RefCell<ProverTracker<B>>> =
                Weak::upgrade(self_rc).ok_or_else(|| {
                    SnarkError::SetupError(NoRangePoly(
                        "contig_one_poly requires a tracker handle; self_rc is dead".to_string(),
                    ))
                })?;
            tracker_rc
        } else {
            return Err(SnarkError::SetupError(NoRangePoly(
                "contig_one_poly requires a tracker handle; none available".to_string(),
            )));
        };

        let tracked = TrackedPoly::new(Either::Left(poly_id), nv, tracker_rc);
        self.state
            .indexed_tracked_polys
            .insert(label, tracked.clone());
        Ok(tracked)
    }

    /// Deterministically reduces the degree of the single aggregated sumcheck claim.
    ///
    /// Algorithm:
    /// 1) Expand each claim term only until it is a product of *atoms*.
    ///    - Atom = material MLE, or a linear virtual polynomial
    ///      (sum of single-factor terms / scalar-times-MLE).
    ///    - We do *not* distribute atom products. For example, `(a+b)(c+d)` stays
    ///      as two factors if both factors are atoms.
    /// 2) While some terms exceed `SUMCHECK_TERM_DEGREE_LIMIT`, find the most
    ///    frequent contiguous size-`LIMIT` chunk among oversized terms.
    /// 3) Commit that chunk polynomial once, replace chunk occurrences by the new
    ///    tracked id, and add the corresponding zerocheck link constraint.
    ///
    /// The procedure is fully deterministic (stable ordering/tie-breaks) and
    /// mirrors verifier-side reduction.
    fn reduce_sumcheck_dgree(&mut self) -> SnarkResult<()> {
        const MAX_TERM_DEGREE: usize = crate::SUMCHECK_TERM_DEGREE_LIMIT;

        debug_assert!(
            self.state.mv_pcs_substate.zero_check_claims.is_empty(),
            "reduce_sumcheck_dgree expects no zerocheck claims"
        );
        debug_assert_eq!(
            self.state.mv_pcs_substate.sum_check_claims.len(),
            1,
            "reduce_sumcheck_dgree expects exactly one sumcheck claim"
        );

        let mut chunk_cache: BTreeMap<Vec<TrackerID>, TrackerID> = BTreeMap::new();
        let mut atom_cache: BTreeMap<TrackerID, bool> = BTreeMap::new();
        let mut extra_zero_claims: Vec<TrackerID> = Vec::new();
        let mut eval_cache: BTreeMap<(TrackerID, usize), Vec<B::F>> = BTreeMap::new();
        let mut committed_chunks: usize = 0;
        let mut oversized_terms_reduced: usize = 0;
        let mut claims_reduced: usize = 0;
        let mut rounds: usize = 0;
        let mut replacements: usize = 0;
        let mut expanded_terms_total: usize = 0;
        let mut expanded_oversized_terms: usize = 0;
        let mut total_terms: usize = 0;

        fn is_atom<B: SnarkBackend>(
            tracker: &ProverTracker<B>,
            id: TrackerID,
            memo: &mut BTreeMap<TrackerID, bool>,
        ) -> bool {
            if let Some(v) = memo.get(&id) {
                return *v;
            }
            let ans = if tracker.mat_mv_poly(id).is_some() {
                true
            } else if let Some(vpoly) = tracker.virt_poly(id) {
                vpoly.iter().all(|(_, term)| {
                    term.len() <= 1 && term.iter().all(|child| is_atom(tracker, *child, memo))
                })
            } else {
                false
            };
            memo.insert(id, ans);
            ans
        }

        fn expand_to_atoms<B: SnarkBackend>(
            tracker: &ProverTracker<B>,
            id: TrackerID,
            atom_memo: &mut BTreeMap<TrackerID, bool>,
            expand_memo: &mut BTreeMap<TrackerID, Vec<(B::F, Vec<TrackerID>)>>,
        ) -> Vec<(B::F, Vec<TrackerID>)> {
            if let Some(cached) = expand_memo.get(&id) {
                return cached.clone();
            }
            if is_atom(tracker, id, atom_memo) || tracker.mat_mv_poly(id).is_some() {
                return vec![(B::F::one(), vec![id])];
            }
            let Some(vpoly) = tracker.virt_poly(id) else {
                return vec![(B::F::one(), vec![id])];
            };

            let mut out: Vec<(B::F, Vec<TrackerID>)> = Vec::new();
            for (coeff, factors) in vpoly.iter() {
                let mut acc: Vec<(B::F, Vec<TrackerID>)> = vec![(B::F::one(), Vec::new())];
                for factor_id in factors.iter().copied() {
                    let factor_terms = expand_to_atoms(tracker, factor_id, atom_memo, expand_memo);
                    let mut next: Vec<(B::F, Vec<TrackerID>)> =
                        Vec::with_capacity(acc.len() * factor_terms.len());
                    for (lhs_coeff, lhs_ids) in acc.into_iter() {
                        for (rhs_coeff, rhs_ids) in factor_terms.iter() {
                            let mut ids = lhs_ids.clone();
                            ids.extend_from_slice(rhs_ids);
                            next.push((lhs_coeff * *rhs_coeff, ids));
                        }
                    }
                    acc = next;
                }
                for (acc_coeff, ids) in acc.into_iter() {
                    out.push((*coeff * acc_coeff, ids));
                }
            }
            expand_memo.insert(id, out.clone());
            out
        }

        fn eval_vector<B: SnarkBackend>(
            tracker: &ProverTracker<B>,
            id: TrackerID,
            target_nv: usize,
            cache: &mut BTreeMap<(TrackerID, usize), Vec<B::F>>,
        ) -> Vec<B::F> {
            if let Some(v) = cache.get(&(id, target_nv)) {
                return v.clone();
            }

            let target_len = 1usize << target_nv;
            let res = if let Some(mat) = tracker.mat_mv_poly(id) {
                let base = mat.evaluations();
                if base.len() == target_len {
                    base
                } else {
                    let mut expanded = Vec::with_capacity(target_len);
                    let repeat = target_len / base.len();
                    for _ in 0..repeat {
                        expanded.extend_from_slice(&base);
                    }
                    expanded
                }
            } else if let Some(vpoly) = tracker.virt_poly(id) {
                let mut acc = vec![B::F::zero(); target_len];
                for (coeff, factors) in vpoly.iter() {
                    let mut term = vec![*coeff; target_len];
                    for fid in factors.iter().copied() {
                        let fv = eval_vector(tracker, fid, target_nv, cache);
                        cfg_iter_mut!(term).zip(fv).for_each(|(a, b)| *a *= b);
                    }
                    cfg_iter_mut!(acc).zip(term).for_each(|(a, b)| *a += b);
                }
                acc
            } else {
                vec![B::F::zero(); target_len]
            };
            cache.insert((id, target_nv), res.clone());
            res
        }

        fn find_subslice(haystack: &[TrackerID], needle: &[TrackerID]) -> Option<usize> {
            if needle.is_empty() || haystack.len() < needle.len() {
                return None;
            }
            haystack.windows(needle.len()).position(|w| w == needle)
        }

        fn reduce_poly<B: SnarkBackend>(
            tracker: &mut ProverTracker<B>,
            poly_id: TrackerID,
            chunk_cache: &mut BTreeMap<Vec<TrackerID>, TrackerID>,
            atom_cache: &mut BTreeMap<TrackerID, bool>,
            extra_zero_claims: &mut Vec<TrackerID>,
            eval_cache: &mut BTreeMap<(TrackerID, usize), Vec<B::F>>,
            committed_chunks: &mut usize,
            oversized_terms_reduced: &mut usize,
            rounds: &mut usize,
            replacements: &mut usize,
            expanded_terms_total: &mut usize,
            expanded_oversized_terms: &mut usize,
        ) -> SnarkResult<TrackerID> {
            if tracker.mat_mv_poly(poly_id).is_some() {
                return Ok(poly_id);
            }
            let virt_poly = match tracker.virt_poly(poly_id) {
                Some(poly) => poly.clone(),
                None => return Ok(poly_id),
            };

            let mut expand_memo: BTreeMap<TrackerID, Vec<(B::F, Vec<TrackerID>)>> = BTreeMap::new();
            let mut terms: Vec<(B::F, Vec<TrackerID>)> = Vec::new();
            for (coeff, ids) in virt_poly.iter() {
                let mut acc: Vec<(B::F, Vec<TrackerID>)> = vec![(B::F::one(), Vec::new())];
                for factor_id in ids.iter().copied() {
                    let expanded =
                        expand_to_atoms(tracker, factor_id, atom_cache, &mut expand_memo);
                    let mut next: Vec<(B::F, Vec<TrackerID>)> =
                        Vec::with_capacity(acc.len() * expanded.len());
                    for (lhs_coeff, lhs_ids) in acc.into_iter() {
                        for (rhs_coeff, rhs_ids) in expanded.iter() {
                            let mut joined = lhs_ids.clone();
                            joined.extend_from_slice(rhs_ids);
                            next.push((lhs_coeff * *rhs_coeff, joined));
                        }
                    }
                    acc = next;
                }
                for (acc_coeff, acc_ids) in acc.into_iter() {
                    let c = *coeff * acc_coeff;
                    if !c.is_zero() {
                        terms.push((c, acc_ids));
                    }
                }
            }
            let claim_term_count = terms.len();
            let claim_oversized = terms
                .iter()
                .filter(|(_, ids)| ids.len() > MAX_TERM_DEGREE)
                .count();
            let claim_max_degree = terms.iter().map(|(_, ids)| ids.len()).max().unwrap_or(0);
            *oversized_terms_reduced += claim_oversized;
            *expanded_terms_total += claim_term_count;
            *expanded_oversized_terms += claim_oversized;
            debug!(
                claim_id = ?poly_id,
                claim_term_count,
                claim_oversized,
                claim_max_degree,
                "sumcheck degree reduction claim stats"
            );

            let atom_refs = terms
                .iter()
                .flat_map(|(_, ids)| ids.iter())
                .filter(|id| is_atom(tracker, **id, atom_cache))
                .count();
            debug!(
                claim_id = ?poly_id,
                atom_refs,
                "sumcheck degree reduction atomized claim"
            );

            fn commit_chunk<B: SnarkBackend>(
                tracker: &mut ProverTracker<B>,
                chunk: &[TrackerID],
                chunk_cache: &mut BTreeMap<Vec<TrackerID>, TrackerID>,
                extra_zero_claims: &mut Vec<TrackerID>,
                eval_cache: &mut BTreeMap<(TrackerID, usize), Vec<B::F>>,
                committed_chunks: &mut usize,
            ) -> SnarkResult<TrackerID> {
                if let Some(id) = chunk_cache.get(chunk).copied() {
                    return Ok(id);
                }
                // Keep all newly committed chunk polynomials on the global max domain.
                // `equalize_mat_poly_nv` already lifted existing materialized polynomials
                // to this nv before sumcheck compilation; using a smaller nv here would
                // re-introduce mixed-nv products and break HP virtual-poly construction.
                let nv = tracker.state.num_vars.values().max().copied().unwrap_or(0);
                let mut evals = vec![B::F::one(); 1 << nv];
                for id in chunk.iter().copied() {
                    let v = eval_vector(tracker, id, nv, eval_cache);
                    cfg_iter_mut!(evals).zip(v).for_each(|(a, b)| *a *= b);
                }
                let mle = Arc::new(MLE::from_evaluations_vec(nv, evals.clone()));
                let prover_param = tracker.pk.mv_pcs_param.clone();
                let com = B::MvPCS::commit(prover_param.as_ref(), &mle)?;
                let committed_id = tracker.track_mat_mv_p_and_commitment(&mle, com)?;
                chunk_cache.insert(chunk.to_vec(), committed_id);
                *committed_chunks += 1;
                eval_cache.insert((committed_id, nv), evals);
                let mut chunk_poly = VirtualPoly::new();
                chunk_poly.push((B::F::one(), chunk.to_vec()));
                let chunk_id = tracker.track_virt_poly(chunk_poly);
                let neg_committed = tracker.mul_scalar(committed_id, -B::F::one());
                let diff_id = tracker.add_polys(chunk_id, neg_committed);
                extra_zero_claims.push(diff_id);
                Ok(committed_id)
            }

            while terms.iter().any(|(_, ids)| ids.len() > MAX_TERM_DEGREE) {
                *rounds += 1;
                let mut freq: BTreeMap<Vec<TrackerID>, usize> = BTreeMap::new();
                for (_, ids) in terms.iter().filter(|(_, ids)| ids.len() > MAX_TERM_DEGREE) {
                    for window in ids.windows(MAX_TERM_DEGREE) {
                        *freq.entry(window.to_vec()).or_insert(0) += 1;
                    }
                }
                let mut candidates: Vec<(Vec<TrackerID>, usize)> = freq.into_iter().collect();
                candidates.sort_by(|(a_ids, a_cnt), (b_ids, b_cnt)| {
                    b_cnt.cmp(a_cnt).then_with(|| a_ids.cmp(b_ids))
                });
                let chosen = if let Some((chunk, _)) = candidates.first() {
                    chunk.clone()
                } else {
                    terms
                        .iter()
                        .find(|(_, ids)| ids.len() > MAX_TERM_DEGREE)
                        .and_then(|(_, ids)| ids.get(0..MAX_TERM_DEGREE).map(|s| s.to_vec()))
                        .expect("at least one oversized term must exist")
                };

                let committed_id = commit_chunk(
                    tracker,
                    &chosen,
                    chunk_cache,
                    extra_zero_claims,
                    eval_cache,
                    committed_chunks,
                )?;

                let mut replaced_in_round = 0usize;
                for (_, ids) in terms
                    .iter_mut()
                    .filter(|(_, ids)| ids.len() > MAX_TERM_DEGREE)
                {
                    while ids.len() > MAX_TERM_DEGREE {
                        let Some(pos) = find_subslice(ids, &chosen) else {
                            break;
                        };
                        ids.splice(pos..pos + chosen.len(), [committed_id]);
                        replaced_in_round += 1;
                    }
                }
                if replaced_in_round == 0 {
                    if let Some((_, ids)) = terms
                        .iter_mut()
                        .find(|(_, ids)| ids.len() > MAX_TERM_DEGREE)
                    {
                        ids.splice(0..MAX_TERM_DEGREE, [committed_id]);
                        replaced_in_round = 1;
                    }
                }
                *replacements += replaced_in_round;
            }

            let mut new_poly = VirtualPoly::new();
            for (coeff, ids) in terms.into_iter() {
                if !coeff.is_zero() {
                    new_poly.push((coeff, ids));
                }
            }
            let new_id = tracker.track_virt_poly(new_poly);
            Ok(new_id)
        }

        let reduce_span = tracing::debug_span!("reduce_sumcheck_degree");
        let _reduce_guard = reduce_span.enter();

        let sum_claims = take(&mut self.state.mv_pcs_substate.sum_check_claims);
        for claim in sum_claims.into_iter() {
            claims_reduced += 1;
            let new_id = reduce_poly(
                self,
                claim.id(),
                &mut chunk_cache,
                &mut atom_cache,
                &mut extra_zero_claims,
                &mut eval_cache,
                &mut committed_chunks,
                &mut oversized_terms_reduced,
                &mut rounds,
                &mut replacements,
                &mut expanded_terms_total,
                &mut expanded_oversized_terms,
            )?;
            self.state
                .mv_pcs_substate
                .sum_check_claims
                .push(TrackerSumcheckClaim::new(new_id, claim.claim()));
            if let Some(vpoly) = self.virt_poly(new_id) {
                total_terms += vpoly.len();
            }
        }

        let extra_zero_claims_len = extra_zero_claims.len();
        for id in extra_zero_claims {
            self.add_mv_zerocheck_claim(id)?;
        }

        debug!(
            committed_chunks,
            extra_zerochecks_added = extra_zero_claims_len,
            oversized_terms_reduced,
            rounds,
            replacements,
            expanded_terms_total,
            expanded_oversized_terms,
            claims_reduced,
            total_terms,
            "sumcheck degree reduction stats"
        );

        Ok(())
    }

    #[instrument(level = "debug", skip(self))]
    fn batch_nozero_check_claims(&mut self) -> SnarkResult<()> {
        const NOZERO_CHUNK_SIZE: usize = 1;
        let nozero_claims = take(&mut self.state.mv_pcs_substate.no_zero_check_claims);
        if nozero_claims.is_empty() {
            return Ok(());
        }

        // Use the largest nv in the tracker so all committed chunk polys share a domain.
        let max_nv = self.state.num_vars.values().max().copied().unwrap_or(0);
        let num_claims = nozero_claims.len();
        let mut chunk_comm_ids = Vec::new(); // committed chunk products (materialized)
        let mut master_prod_id = None; // virtual product of chunk commitments
        let mut master_evals: Option<Vec<B::F>> = None; // evals of the same product

        for chunk in nozero_claims.chunks(NOZERO_CHUNK_SIZE) {
            let mut iter = chunk.iter();
            let first = iter
                .next()
                .expect("nozero_claims chunk should be non-empty");
            // 1) Multiply polynomials in the chunk (virtual product + evals).
            let mut chunk_prod_id = first.id();
            let mut chunk_evals = self.evaluations(first.id());
            for claim in iter {
                let id = claim.id();
                chunk_prod_id = self.mul_polys(chunk_prod_id, id);
                let evals = self.evaluations(id);
                debug_assert_eq!(chunk_evals.len(), evals.len());
                cfg_iter_mut!(chunk_evals)
                    .zip(evals)
                    .for_each(|(a, b)| *a *= b);
            }

            // 2) Expand evals to max_nv (by repetition) and commit to the chunk product.
            let base_len = chunk_evals.len();
            debug_assert!(base_len.is_power_of_two());
            let base_nv = base_len.trailing_zeros() as usize;
            if base_nv < max_nv {
                let expand = 1usize << (max_nv - base_nv);
                let mut expanded = Vec::with_capacity(base_len * expand);
                // Keep evaluation ordering consistent with `MLE::new(..., Some(max_nv))`,
                // which repeats the whole evaluation vector cyclically.
                for _ in 0..expand {
                    expanded.extend_from_slice(&chunk_evals);
                }
                chunk_evals = expanded;
            }
            let chunk_mle = MLE::from_evaluations_vec(max_nv, chunk_evals.clone());
            let chunk_comm_id = self.track_and_commit_mat_mv_p(&chunk_mle)?;
            // Link committed chunk to its virtual definition: c_i - prod_i == 0.
            let diff_id = self.sub_polys(chunk_comm_id, chunk_prod_id);
            self.add_mv_zerocheck_claim(diff_id)?;

            // 3) Accumulate committed chunks into a master product (virtual + evals).
            master_prod_id = Some(match master_prod_id {
                None => chunk_comm_id,
                Some(acc) => self.mul_polys(acc, chunk_comm_id),
            });
            master_evals = Some(match master_evals {
                None => chunk_evals,
                Some(mut acc) => {
                    debug_assert_eq!(acc.len(), chunk_evals.len());
                    cfg_iter_mut!(acc)
                        .zip(chunk_evals)
                        .for_each(|(a, b)| *a *= b);
                    acc
                }
            });
            chunk_comm_ids.push(chunk_comm_id);
        }

        let master_prod_id = master_prod_id.expect("nozero_claims should be non-empty");
        let mut master_evals = master_evals.expect("nozero_claims should be non-empty");

        debug!(
            "{} nozerocheck polynomials chunked into {}; final degree {}",
            num_claims,
            chunk_comm_ids.len(),
            self.virt_poly_degree(master_prod_id)
        );

        // 4) Commit to the inverse of the master product and enforce prod * inv == 1.
        batch_inversion(&mut master_evals);
        let inverses_mle = MLE::from_evaluations_vec(max_nv, master_evals);
        let inverses_poly_id = self.track_and_commit_mat_mv_p(&inverses_mle)?;

        let prod_inv_id = self.mul_polys(master_prod_id, inverses_poly_id);
        let diff_id = self.add_scalar(prod_inv_id, -B::F::one());
        self.add_mv_zerocheck_claim(diff_id)?;

        Ok(())
    }

    /// Reduces every zero-check claim, sum-check claim in
    /// the prover state, into a list of evaluation claims. These evaluation
    /// claims will be proved using a PCS
    #[instrument(level = "debug", skip(self))]
    fn compile_sc_subproof(
        &mut self,
        max_nv: usize,
    ) -> SnarkResult<Option<SumcheckSubproof<B::F>>> {
        self.batch_nozero_check_claims()?;
        // Batch all the zero-check claims into one claim, remove old zerocheck claims
        self.batch_z_check_claims()?;
        // Convert the only zerocheck claim to a sumcheck claim
        self.z_check_claim_to_s_check_claim(max_nv)?;
        // Batch all the sumcheck claims into one sumcheck claim
        let mut individual_sumcheck_claims = self.batch_s_check_claims()?;
        if self.state.mv_pcs_substate.sum_check_claims.is_empty() {
            debug!("No sumcheck claims to prove",);
            return Ok(None);
        }

        // Reduce high-degree terms deterministically before sumcheck.
        self.reduce_sumcheck_dgree()?;

        // Batch all the zero-check claims into one claim, remove old zerocheck claims
        self.batch_z_check_claims()?;
        // Convert the only zerocheck claim to a sumcheck claim
        self.z_check_claim_to_s_check_claim(max_nv)?;
        // Batch all the sumcheck claims into one sumcheck claim
        let additional_sumcheck_claims = self.batch_s_check_claims()?;
        for (id, claim) in additional_sumcheck_claims {
            individual_sumcheck_claims.entry(id).or_insert(claim);
        }
        // if self.state.mv_pcs_substate.sum_check_claims.is_empty() {
        //     debug!("No sumcheck claims to prove",);
        //     return Ok(None);
        // }
        // Perform the one batched sumcheck
        let (sc_proof, sc_aux_info) = self.perform_single_sumcheck()?;
        // Assemble the sumcheck subproof of the prover
        let sc_subproof = SumcheckSubproof::new(
            sc_proof.clone(),
            sc_aux_info.clone(),
            individual_sumcheck_claims,
        );
        Ok(Some(sc_subproof))
    }

    /// Compiles the PCS subproof, a proof containg (a) a list of comitments to
    /// the polynomials that the verifier needs oracle access to (b) a query
    /// map, which is the list of all the possible verifier queries to these
    /// comitments (c) a batch opening proof corresponding to the query map
    #[instrument(level = "debug", skip(self))]
    pub fn compile_mv_pcs_subproof(&mut self) -> SnarkResult<PCSSubproof<B::F, B::MvPCS>> {
        let mut query_map: BTreeMap<TrackerID, BTreeMap<PointID, B::F>> = BTreeMap::new();
        let mut point_map: BTreeMap<PointID, Vec<B::F>> = BTreeMap::new();
        let mut point_to_id: BTreeMap<Vec<B::F>, PointID> = BTreeMap::new();
        let mut next_point_id = 0usize;
        let mut mat_polys = Vec::new();
        let mut points = Vec::new();
        let mut evals = Vec::new();
        for claim in &self.state.mv_pcs_substate.eval_claims {
            let eval_id = claim.id();
            let eval_point = claim.point();
            let mat_ids = self.extract_mv_openable_ids(eval_id);
            let point_id = *point_to_id.entry(eval_point.clone()).or_insert_with(|| {
                let pid = PointID::from_usize(next_point_id);
                next_point_id += 1;
                point_map.insert(pid, eval_point.clone());
                pid
            });
            for mat_id in mat_ids {
                let eval = self.evaluate_mv(mat_id, eval_point).unwrap();
                query_map.entry(mat_id).or_default().insert(point_id, eval);
                mat_polys.push(self.mat_mv_poly(mat_id).unwrap().clone());
                points.push(eval_point.clone());
                evals.push(eval);
            }
        }

        let opening_proof: PCSOpeningProof<B::F, B::MvPCS>;
        if mat_polys.len() == 1 {
            let single_proof = B::MvPCS::open(
                self.pk.mv_pcs_param.as_ref(),
                &mat_polys[0],
                &points[0],
                None,
            )?;
            opening_proof = PCSOpeningProof::SingleProof(single_proof.0);
            assert!(single_proof.1 == evals[0]);
        } else if mat_polys.len() > 1 {
            let batch_proof = B::MvPCS::multi_open(
                self.pk.mv_pcs_param.as_ref(),
                &mat_polys,
                &points,
                &evals,
                &mut self.state.transcript,
            )?;
            opening_proof = PCSOpeningProof::BatchProof(batch_proof);
        } else {
            opening_proof = PCSOpeningProof::Empty;
        }

        // Perform the batch-opening

        Ok(PCSSubproof {
            query_map,
            point_map,
            opening_proof,
            comitments: self.state.mv_pcs_substate.materialized_comms.clone(),
        })
    }

    /// Compiles the PCS subproof, a proof containg (a) a list of comitments to
    /// the polynomials that the verifier needs oracle access to (b) a query
    /// map, which is the list of all the possible verifier queries to these
    /// comitments (c) a batch opening proof corresponding to the query map
    #[instrument(level = "debug", skip(self))]
    pub fn compile_uv_pcs_subproof(&mut self) -> SnarkResult<PCSSubproof<B::F, B::UvPCS>> {
        let mut query_map: BTreeMap<TrackerID, BTreeMap<PointID, B::F>> = BTreeMap::new();
        let mut point_map: BTreeMap<PointID, B::F> = BTreeMap::new();
        let mut point_to_id: BTreeMap<B::F, PointID> = BTreeMap::new();
        let mut next_point_id = 0usize;
        let mut mat_polys = Vec::new();
        let mut points = Vec::new();
        let mut evals = Vec::new();
        for claim in &self.state.uv_pcs_substate.eval_claims {
            let eval_id = claim.id();
            let eval_point = claim.point();
            let mat_ids = self.extract_uv_openable_ids(eval_id);
            let point_id = *point_to_id.entry(*eval_point).or_insert_with(|| {
                let pid = PointID::from_usize(next_point_id);
                next_point_id += 1;
                point_map.insert(pid, *eval_point);
                pid
            });
            for mat_id in mat_ids {
                let eval = self.evaluate_uv(mat_id, eval_point).unwrap();
                query_map.entry(mat_id).or_default().insert(point_id, eval);
                mat_polys.push(self.mat_uv_poly(mat_id).unwrap().clone());
                points.push(*eval_point);
                evals.push(eval);
            }
        }

        let opening_proof: PCSOpeningProof<B::F, B::UvPCS>;
        if mat_polys.len() == 1 {
            let single_proof = B::UvPCS::open(
                self.pk.uv_pcs_param.as_ref(),
                &mat_polys[0],
                &points[0],
                None,
            )?;
            opening_proof = PCSOpeningProof::SingleProof(single_proof.0);
            assert!(single_proof.1 == evals[0]);
        } else if mat_polys.len() > 1 {
            let batch_proof = B::UvPCS::multi_open(
                self.pk.uv_pcs_param.as_ref(),
                &mat_polys,
                &points,
                &evals,
                &mut self.state.transcript,
            )?;
            opening_proof = PCSOpeningProof::BatchProof(batch_proof);
        } else {
            opening_proof = PCSOpeningProof::Empty;
        }

        // Perform the batch-opening

        Ok(PCSSubproof {
            query_map,
            point_map,
            opening_proof,
            comitments: self.state.uv_pcs_substate.materialized_comms.clone(),
        })
    }

    /// Compiled the final proof, which contains three subproofs:
    /// 1. The batched sumcheck subproof
    /// 2. The multivariate PCS subproof
    /// 3. The univariate PCS subproof
    #[instrument(level = "debug", skip(self))]
    pub fn compile_proof(&mut self) -> SnarkResult<SNARKProof<B>>
    where
        B: SnarkBackend,
    {
        // Transform all the materialized polynomials to polynomials with the maximum
        // number of variables needed
        let max_nv = self.equalize_mat_poly_nv();
        // Assemble and output the final proof
        let proof = SNARKProof {
            sc_subproof: self.compile_sc_subproof(max_nv)?,
            mv_pcs_subproof: self.compile_mv_pcs_subproof()?,
            uv_pcs_subproof: self.compile_uv_pcs_subproof()?,
            miscellaneous_field_elements: self.state.miscellaneous_field_elements.clone(),
        };
        self.state.miscellaneous_field_elements.clear();
        Ok(proof)
    }
}
